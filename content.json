{"meta":{"title":"This is my Blog","subtitle":"","description":"","author":"Kwon Jung Min","url":"https://KJM94.github.io","root":"/"},"pages":[],"posts":[{"title":"Bubble_sort","slug":"Bubble-sort","date":"2021-06-05T16:44:10.000Z","updated":"2021-06-05T16:45:36.976Z","comments":true,"path":"2021/06/06/Bubble-sort/","link":"","permalink":"https://kjm94.github.io/2021/06/06/Bubble-sort/","excerpt":"","text":"버블 정렬 무작위의 정수값을 배열에 넣은 후 오름차순 정렬 1234567891011121314151617181920212223242526272829303132333435363738394041package test1;import java.util.Scanner;import java.util.List;import java.util.ArrayList;import java.util.Collections;public class prac &#123; public static void main(String[] args) &#123; &#x2F;&#x2F; TODO Auto-generated method stub int inum; &#x2F;&#x2F; 입력받을 배열 수 int i; int nnum; &#x2F;&#x2F; 배열에 들어갈 숫자 List nlist &#x3D; new ArrayList(); Scanner input &#x3D; new Scanner(System.in); System.out.print(&quot;배열 수 입력 : &quot;); inum &#x3D; input.nextInt(); for(i &#x3D; 0; i &lt; inum; i++) &#123; System.out.print(&quot;배열에 들어갈 숫자 : &quot;); nnum &#x3D; input.nextInt(); nlist.add(nnum); &#125; System.out.print(&quot;정렬 전 배열 : &quot;); System.out.println(nlist); Collections.sort(nlist); &#x2F;&#x2F; 오름차순 정렬 System.out.print(&quot;정렬 후 배열 : &quot;); System.out.println(nlist); &#125;&#125;","categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://kjm94.github.io/tags/Java/"}]},{"title":"Team_Project_No.3","slug":"Team-Project-No-3","date":"2021-06-04T04:54:29.000Z","updated":"2021-06-04T17:32:39.726Z","comments":true,"path":"2021/06/04/Team-Project-No-3/","link":"","permalink":"https://kjm94.github.io/2021/06/04/Team-Project-No-3/","excerpt":"","text":"Team Project 3신용카드 사용자 연체 예측 AI 경진대회 언어 및 작업툴: Python 인원: 3명 기간: 2021.04.05 - 2021.05.24 내용 신용카드 사용자 데이터를 보고 사용자의 대금 연체 정도를 예측하는 알고리즘 개발 기여: xgboost 등 기법을 사용하여 정형 데이터 가공 결과: 1,506팀 중 404등 최종점수 - 0.70742","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"[Deep Learning] YOLO, YOLOv2 and YOLOv3 비교","slug":"yolo비교_jej","date":"2021-05-31T15:00:00.000Z","updated":"2021-06-04T17:32:39.745Z","comments":true,"path":"2021/06/01/yolo비교_jej/","link":"","permalink":"https://kjm94.github.io/2021/06/01/yolo%EB%B9%84%EA%B5%90_jej/","excerpt":"","text":"references https://amrokamal-47691.medium.com/yolo-yolov2-and-yolov3-all-you-want-to-know-7e3e92dc4899 YOLO, YOLOv2 and YOLOv3 Object Detection : Deep Learning의 Computer vision 분야에서 가장 주목받는 주제 중 하나이다. EX) RCNN, RetinaNet and YOLO(you only look once) 1. Object Detection 이미지 혹은 비디오 스트림이 주어지면, object detection 모델은 객체들의 모임 중에서 어떤 것이 존재할 수 있는지 식별하며 이미지 안에서 그들의 위치들에 대해 정보를 제공할 수 있다. Object Detection은 single object를 분류하고 이미지에서 그 object의 위치를 결정하는 classification with localization과는 다르다. 1-1. IOU(Intersect Over Union) IOU는 교차 영역을 두 box의 전체 영역으로 나누어 계산할 수 있다. IOU는 0과 1사이 아래의 그림에서 왼쪽 사진은 교차영역이 오른쪽 사진보다 작다.오른쪽 사진은 거의 완벽하게 교차하였기 때문에 IOU는 1에 가까워지는 것이다. 1-2. Precision(정밀도) Precision(정밀도)는 진양성을 양성예측으로 나눈 것으로 정의할 수 있다. 예를 들어 20 개의 이미지가 있고 20개의 이미지에서 120대의 자동차가 있다는 것을 알고 있다고 가정 이미지를 모델에 입력하고 -&gt; 100대의 자동차를 감지했다고 가정 20개가 잘못된 경우 정밀도는 80/100 = 0.8 이다. 만약 예측된 box와 ground truth box 사이의 IOU가 임계값(0.5,0.75,..)보다 작으면 부정확한 예측이 될 수 있다. 1-3. Recall(재현율) 위의 정밀도를 구하는 예제를 봤을 때, 자동차의 total 갯수를 고려하지 않았다. 그래서 120대 대신에 1000대의 자동차들을 사용한다고 가정하고, 그 모델 output이 80대가 있는 100개의 box가 맞다면 Precision은 다시 0.8이 된다. 그렇다면 이 문제를 해결하기 위해 우리는 재현율이라는 개념을 사용해야 한다. 아래의 식과 같으며 Recall은 진양성에서 실제 양성으로 나눈 것으로 정의할 수 있다. recall = 80/120 = 0.667 재현율이 데이터에서 object들을 detect하는데 좋다는 것을 확인하였다. 1-4. Average Precision and Mean Average Precision(mAP) Average Precision을 간략하게 정의하면 Precision-Recall Curve의 아래에 있는 영역을 의미한다. AP는 Precision과 Recall을 결합한 것이다. AP는 0과 1사이에 존재하며, 높을 수록 더 좋은 것이다. AP=1을 얻기위해서는 Precision과 Recall이 1로 같아야한다. mAP는 모든 class에 대해 계산된 AP의 평균을 의미한다. 2. YOLO YOLO란?? 많은 object detection은 이미지의 모든 object를 detect하기 위해 이미지를 한 번 이상 통과해야하거나 object를 detect하기 위해 2-step을 거쳐야 한다. YOLO는 이런 과정을 거칠 필요가 없다 모든 object를 detect하기 위해 이미지를 한 번만 보면 된다. 즉, YOLO(You Only Look Once) 해석 그대로 받아드리면 된다. 실제로 YOLO가 매우 빠른 모델인 이유이다. 3.YOLO (YOLOv1) YOLO는 이미지를 S*S 그리드로 나눈다. EX) 아래의 이미지는 5*5로 나누었으며, 만약에 Grid Cell안에 object가 위치해 있을 때, 그 grid cell은 object를 detect한다. YOLO는 7*7 = 49 grid cell 각각에 대해 동시에 Classification과 Localization 문제를 run한다. Classification과 Localization network는 오직 하나의 object만 detect할 수 있기 때문에 그 말은 즉, 어떤 grid cell은 오직 하나의 object만 detect할 수 있다. 따라서 아래와 같은 문제들을 직면하게 된다. 7*7 grid 를 사용하기 때문에 어느 grid는 하나의 object만 detect할 수 있고, 그 최대 object의 갯수는 49개만 가능하다는 것이다. 만약 grid cell이 하나의 object보다 더 많은 object를 포함하게 된다면?그 모델은 모든 object에 대하여 detect를 할 수 없을 것이다.따라서 Close Object Detection는 YOLO가 겪고 있는 문제이다. Object가 하나의 grid의 면적을 넘어 차지하고 있다면(위의 택시처럼), 그 모델은 한 번이 아니라 다른 grid에서도 taxi라 detect 할 수 있다.따라서 이 문제는 “Non-Max Suppresion”를 사용하여 해결한다. 49개 cell 모두 동시에 detect되어지며, 그것이 바로 YOLO가 매우 빠른 모델인 이유이다. 7*7 gric cell의 각각은 B Bounding boxe들을 예측하고(YOLO chose B =2), 각각의 박스, 모델의 output은 confidence score이다. confidence score 상자가 모델을 포함하는 모델을 얼마나 확신하는지를 반영한다. confidence score을 사용하여 모델이 배경을 감지하지 못하도록 막을 수 있으며 cell에 object가 없으면 confidence score은 0이 되어야한다. 만약 그렇지 않으면, confidence scroe가 예측된 box와 ground truth 사이의 union을 통한 IOU가 같기를 원한다. 왜 C= IOU 인가요? ground truth box는 손으로 그려졌기 때문에 ground truth box 안에 object가 있다는 것을 100% 확신한다. 따라서 truth box안에 있는 높은 IOU를 가진 box는 또한 같은 object를 둘러싸고, IOU가 높을 수록 predict box 내부에 object가 있다는 가능성이 높아진다. 7*7 =49 개의 cell들이 있고 각 cell들에 대해 2개의 상자(total 98개)를 예측함 box의 대부분은 매우 낮은 신뢰도(confidence)를 가지므로 제거할 수 있다. 추가로 confidence score(C)에 모델은 4개의 숫자를 출력한다. ((x,y),w,h)는 predeict bounding box의 위치를 나타낸다. (x,y)는 grid cell의 bound를 기준으로 box의 중심을 나타낸다. width와 height은 전체 이미지를 기준으로 예측된다.\\ YOLO는 20개의 다른 object들의 class들을 detect하도록 훈련되어 진다. 어떤 grid cell에서든지, 그 모델은 20개의 conditional class probabilities를 출력한다. 반면에 각각의 grid cell은 우리에게 2개의 bounding box들 사이의 choice를 주며, 우리는 오직 하나의 class probalility vector를 가질 수 있다. 우리는 가장 낮은 신뢰도를 가진 box를 제거 할 수 있다. 3-1. Output Shape 예측은 SxSx(Bx5 + classes) tensor로 암호화되어진다. EX) S=7, B=2, Classes = 20 총 7x7x30 tensor 이다. 3-2. Network Design YOLO는 하나의 Convolutional network를 사용하여 여러개의 bounding box들과 그 box들에 대한 class probabilities를 예측한다. 이 네트워크는 이미지 분류 모델인 GoogleNet에 의해 영향을 받았지만, GoogleNet에 사용되어진 inception 모듈 대신에 YOLO는 단순하게 3x3 convolutional layer(컨볼루션 레이어)와 1x1 reduction layer(축소 레이어)을 사용한다. 24개의 convolution layer와 2개의 완전히 연결된 layer들이 있다. 위에서 언급한 대로, 네트워크의 최종 output은 7x7x30 tensor로 예측한다. 3-3. Loss Function YOLO는 손실함수로서 SSE(Sum-squared Error)를 사용한다. optimize하게에 쉽기 때문이다. 위의 식에서 첫번째, 두번째 식은 localization loss이고,3번째, 4번째 식은 confidence loss이며마지막 식은 classification loss를 나타낸다. 3-4. Training 먼저, ImageNet 1000-class 대회 데이터 셋에서 분류에 대한 네트워크의 convolutional layer들을 사전훈련 시킨다. 사전훈련을 위해 첫 20개 convolutional layer들을 사용했고, 그 다음에 평균 pooling layer와 224x224의 input 사이즈를 가진 1x1000 인 fully connected layer를 사용했다. 이 network는 top-5의 정확도인 88%에 도달했다. 그 다음 1x1000 fully connected layer와 추가적으로 4개의 convolutional layer 그리고 2개의 fully connected layer를 랜덤하게 초기화한 가중치를 더했다. 그리고 224x224 에서 448x448 로부터 네트워크의 input resolution을 증가했다. 그 후 detect를 위해 모델을 훈련시켰다. 3-5. Non-Maximal Suppression YOLO는 7x7 grid를 사용하므로 만약 object가 하나의 grid 보다 더 차지한다면 이 object는 다른 grid에서도 detect될 수 있다. 한번에 하나만 detect되어야 하기 때문에, 예를 들어 아래의 이미지에서 택시의 yellow box가 3개나 dectect 되었다. 실제로 1개만 detect되어야 하는데 세 번 이상 detect 된 격이다. 그렇다면 이 yellow box 들 중 하나만 선택하는 방법은?\\ 각 class에 대해 수행하자\\ C &lt; C 임계 값(ex.C &lt; 0.5)를 사용하여 모든 box를 제거한다.\\ 가장 높은 신뢰도 C에서 시작하여 예측을 정렬한다.\\ C가 가장 높은 상자를 선택하고 예측을 출력한다.\\ 이전 단계의 box와 함께 IOU&gt;IOU-treshold 가 있는 box들을 모두 제거한다.\\ 모든 나머지 예측을 확인할 때 까지 4단계부터 다시 시작한다. Non-Maximal Suppresion 에서 2-3%를 추가한다. 3-6. Fast YOLO and YOLO VGG-16 Fast YOLO는 YOLO의 빠른 버전이다. fast YOLO는 24개 대신에 9개의 convolutional layer을 사용한다. YOLO보다 더 빠르지만 더 낮은 mAP를 가진다. YOLO VGG-16은 오리지널 YOLO 네트워크 대신에 그것의 backbone을 VGG-16을 사용한다. 좀 더 정확하지만 실시간보다 좀 더 느리다. 3-7. Limitations of YOLO 각각의 grid cell은 오직 2개의 box들을 사용하여 예측하고 하나의 class만 예측할 수 있기 때문에 YOLO가 예측할 수있는 nearby object의 수를 제한한다. 특히 새의 무리와 같이 그룹을 나타내는 작은 object의 경우에 그러하다. YOLO는 7x7 = 49개의 물체만 감지할 수 있다. 비교적 높은 localization 오류 4. YOLOv2 YOLO ver1은 상당히 많은 localization error들을 만든다. 게다가, YOLO는 비교적 낮은 재현율을 보인다. 그러므로 YOLO의 두번째 버전은 classification accuracy를 유지하면서 localization(위치)과 재현율을 향상시키는 것이 목표이다. 아래의 방법이 YOLOv2의 성능을 좋게 만드는 idea이다. BatchNormalization: YOLO의 모든 컨볼루션 레이어들에 batch normalizaition을 더함으로써 mAP가 2% 향상되었다. High Resolution Classifier: YOLO ver1은 아래와 같이 훈련되어졌다. 224x224에 classifier network를 훈련시켰다. detection을 위해 resolution(해상도)를 448로 증가시켰다. 이 뜻은 detection으로 전환할 때 네트워크가 동시에 학습 object detection으로 전환하고, 새로운 input resolution으로 조정한다. YOLOv2 를 위해 처음에 224x224 인 이미지에 모델을 훈련시키는 동안, full 448x448 이미지에 classification network를 fine tune한다 (dectection을 하기 위한 훈련 전에 ImageNet의 10 epochs 에 대해). 더 높은 resolution input에 더 나은 동작을 하도록 그것의 filter들을 조절하기 위한 network 시간을 제공한다. high-resolution classification network는 거의 4% 증가된 mAP를 제공한다. Convolutional With Anchor Boxes(한 cell당 여러개의 object 예측) YOLOv1은 object의 중심을 포함하는 grid cell에 object를 할당하려한다. 이 아이디어를 사용하여 위의 이미지에 빨간 셀에는 man과 necktie를 감지해야한다. 그러나 grid cell은 오직 하나의 cell에 하나의 object만 detect할 수 있다. 이것을 해결하기 위해 저자는 k bounding box를 이용해 하나의 object보다 더 많은 object를 detect하도록 했다. &gt; k bounding box를 예측하기 위해 YOLOv2는 Anchor boxes의 아이디어를 사용했다. 4-1. Anchor Box 그렇다면 Anchor Box는 무엇일까? YOLO는 컨볼루션 feature extractor의 위에서 완전히 연결된 layer들을 사용해서 바로 bounding box들의 좌표를 예측한다. 좌표를 바로 예측하는 대신에 Fater R-CNN인 다른 object detection 모델은 내가 직접 고른 anchor box들을 사용해서 bounding box를 예측한다. 우리는 이미지를 기준으로 박스의 예측하는 것 대신에 bounding box를 기준으로 bounding box를 예측할 수 있다. 이 아이디어를 사용해서 network가 더 쉽게 학습할 수 있다. 오직 컨볼루션 레이어들(완전히 연결된 layer들 제외)들인 Faster R-CNN은 offset과 anchor box들의 신뢰도를 예측한다. 아래의 이미지는 Grid cell(빨간 박스)과 5 anchor box들(노란 박스)과 함께 다른 모양을 가진다. YOLOv2는 손으로 직접 k anchor box를 고르는 것 대신에 anchor box들의 아이디어를 사용하려 한다. detection을 훈련하려는 네트워트를 더 쉽게 만들기 위해 가장 best인 anchor box를 찾으려 한다. 아래의 이미지는 5개의 red box들은 평균 dimension들과 VOC 2007 데이터셋의 object들의 위치를 나타낸다. 왜 5개의 박스들을 가지는지 궁금할 것이다! k-means clustering을 수행하는데 k개의 다양한 값에 대해 훈련 데이터셋의 bounding box에서 실행한다. 가장 가까운 중심으로 평균 IOU를 plot하지만, 유클리디안 거리 방식을 사용하는 대신에 bounding box와 중심 사이의 IOU를 사용한다. 모델의 복잡성과 높은 재현율 사이의 가장 좋은 트레이드오프로써 k=5로 선택된 것이다! YOLOv2는 grid cell의 위치를 기준으로 location coordinate를 예측한다. 이 예측은 ground truth를 0과 1 사이로 제한한다. 네트워크는 각 cell 당 5개의 bounding box들을 예측한다. 즉, 각 bounding box들에 대해 5개의 좌표를 예측한다는 것이다. tx,ty,tw,th 그리고 to 만약 그 cell이 왼쪽 위쪽 코너로 부터 (cx,cy)만큼 오프셋되고, 그리고 bounding box prior(anchor box)에 width, height pw,ph를 가진다면 아래의 예측과 일치한다. 예를 들어, 만약 2개의 anchor box를 gird cell(2,2)에 사용하는데 아래의 이미지에서 2개의 box들(blue, yellow)를 output할 것이다. cell에 해당하는 2 anchor box들을 검정 점 박스가 대표한다. 위의 그림에서 파란 박스만 고려해보자, YOLO ver1에서는 오직 하나의 grid cell로서 예측된 파란 박스를 할당하는 대신에! YOLOv2는 그 grid cell 뿐만 아니라 anchor box들 중 하나까지 할당한다. 그리고 그것은 ground truth box와 함께 가장 높은 IOU를 가진 것이 될 것이다. YOLOv2는 grid와 anchor box에 파란 박스를 할당하기 위해 위의 방정식을 사용한다. 4-2. Network Architecture1) Darknet-19 복잡성과 정확도 문제를 해결하기 위해 저자는 YOLOv2의 backbone으로 사용할 Darknet-19라는 새로운 classification model을 제한했다. Darknet-19는 19개의 컨볼루션 layer들과 5개의 max-pooling 레이어들을 가진다. ImageNet의 top-5의 정확도인 91.2%를 달성했고 그것은 VGG(90%)보다 나으며 YOLO network(88%)보다 높다. 2) Output Shape YOLOv2의 output shape은 13x13x(k.(1+4+20)) 이며 k는 anchor box들의 수이다. 20은 class들의 수 이다. k=5에 대한 output shape은 13x13x125가 될 것이다. 3) Training 그 모델은 classification에 대한 훈련이 처음되고 그 다음 detection에 대한 룬련이 되어진다. (1) Classification: 160 epoch과 224x224인 input shape의 ImageNet 1000 클래스 분류 데이터셋에서 Darknet-19 네트워크를 훈련했고, 그 후 10 epoch동안 448x448인 큰 input 크기로 네트워크를 미세조정하게 된다. 이것은 76.5%의 top-1정확도와 93.3%의 top-5 정확도를 제공한다.(2) Detection: classification 에 대한 훈련 후에 Darknet-19로 부터 마지막 컨볼루션 레이어를 제거한다. 그리고 대신에 3x3 컨볼루션 레이어와 output의 수인 1x1 컨볼루션 레이어를 더한다.(detection에 필요한 13x13x125) 또한, passthrough 레이어는 이전의 레이어로부터 모델에 더 좋은 grain feature들을 사용하기 위하여 추가된다. 그런 다음 detection 데이터셋(VOC, COCO datasets)에 160번의 epoch을 한 network를 훈련시킨다. 4) Multi-scale Training YOLOv2가 서로 다른 크기의 이미지에서 수행되도록 서로 다른 input size에 대해 모델을 훈련시킨다. input size를 수정하는 대신 몇 번의 반복마다 네트워크를 변경한다. 매 10 batches 후에 네트워크는 랜덤하게 새로운 차원 사이즈를 고르는데 dimensions set(320,352,384,…,608)로 부터 구한다. 해당 dimension에 맞게 네트워크 size를 조정하고 훈련을 계속한다. 동일한 네트워크가 다른 resolution에서 물체를 예측할 수있음을 의미한다. 5) Comparision to Other Dectection Systems YOLOv2는 최신식이며 다른 detection 시스템 보다 더 빠르다. 게다가, 다양한 이미지 사이즈에 동작될 수 있다. 속도와 정확도 사이의 부드러운 트레이드 오프를 제공한다.위의 결과: PASCAL VOC2012 테스트 detection위의 결과: COCO test-dev2015 4-3. YOLO9000 20개 class 이상의 detect가 필요할 경우, YOLO9000을 사용하면 된다. 실시간 프레임워크이며 9000개 object 카테고리보다 더 많이 감지하기 위해 사용한다. 또한 detection과 classification을 함께 최적화한다. YOLOv2는 classfication에 대한 훈련 후에 detection 훈련을 한다. 이러한 이유는 하나의 object를 포함하는 classfication에 대한 dataset은 dectection에 대한 데이터셋과 다르다. YOLOv2에서 저자는 classification에 대한 훈련과 dectection data를 함께 훈련하는 매커니즘을 제안한다. 훈련하는 동안, dectection과 classification 데이터셋 둘로 부터 이미지를 섞는다. 네트워크가 dectection을 위한 label된 이미지를 발견하면, full YOLOv2의 손실함수를 기반으로 역전파할 수 있다. detection과 classification data를 섞는 아이디어는 새로운 도전을 직면한다! detection 데이터셋들은 classification 데이터셋들과 비교해서 작다. detection 데이터셋들은 오직 공통인 object들과 일반적인 label만 가진다. 마치 dog 혹은 boat 처럼! 반면에 classification 데이터셋들은 더 넓고 깊은 범위의 label들을 가진다. 예를 들어, ImageNet 데이터셋은 “german shepherd”그리고 “Bedlington terrier”과 같은 개들의 백여가지 보다 더 많은 걸 가진다. 이러한 두 데이터셋들을 병합하기 위해 저자들은 *wordtree라고 부르는 것과 visual comcept들의 계층적 모델들을 만들었다. 모든 클래스들은 ROOT 아래에 위치해 있다. WordTree에서 DarkNet-19 모델을 훈련시켰다. WordTree로 부터 ImageNet 데이터셋의 1000개 class들을 추출했고, intermediate node들을 그것에 추가했다. 그리고 그것은 1000개에서 1369로 label space를 확장했다. 그리고 그것을 WordTree1k라고 불렀다. 지금은 Darknet-19의 output layer의 사이즈는 1000개 대신에 1369개가 되었다. 1369개의 예측들은, 하나의 softmax를 계산하지 않지만 동일한 개념인 분리된 softmax의 전반적인 synset들을 계산한다. Darknet-19에 369개의 추가적인 개념들을 더함에도 불구하고 71.9%의 top-1 정확도와 90.4%의 top-5의 정확도를 달성했다. detector은 bounding box와 tree의 probabilities를 예측하였지만, 둘 이상의 softmax를 사용하기 때문에 우리는 예측된 class들을 찾기위해 tree를 탐색해야 한다. tree의 위에서 아래까지 탐색하는데 threshold-probability보다 작아지는 확률에 도달하기 까지 매 split마다 가장 높은 신뢰도를 가져야 한다. 그리고 object class를 예측한다. 예를 들어, 만약 input image에 dog를 포함한다면, 그 트리의 확률은 아래와 같이 나타난다. 모든 이미지가 object를 가진다고 추정하는 대신에, YOLOv2의 objectness 예측기를 사용하여 root인 Pr(물리적 객체)의 값을 제공한다. 그 모델은 각 branch level에 대한 softmax를 출력한다. 우리가 위에서부터 아래로 움직이면서 가장 높은 확률(만약 threshold value보다 높다면)을 가진 노드를 고른다. 예측은 우리가 멈춘 노드가 될 것이다. 위의 트리에서, 모델은 physical object=&gt; dog =&gt; hunting dog 순으로 겪는다. hunting dog에서 멈출 것이고 sighthound로 내려가지 않을 것이다. 왜냐하면 그것의 신뢰도는 threshold 값보다 더 낮은 신뢰도를 가지기 때문이다. 그래서 그 모델은 sighthound가 아닌 hunting dog를 예측하는 것이다. 5. YOLOv3 전 버전 보다 좀 더 크지만 더 정확하다. 5-1. Bounding Box Prediction YOLO9000과 같이, 네트워크는 각 bounding box마다 4개의 좌표를 예측한다. 만약 그 cell이 (cx,cy)의 위쪽왼쪽 코너로 부터 떨어져있다면 bounding box prior은 width, heigh, Pw,Ph를 가지고 그런 다음 예측은 아래와 같이 일치한다. YOLOv3는 또한 logistic regression을 사용하여 각 bounding box에 대한 신뢰도를 예측한다. 이것은 1이될 것이다. 만약 bounding box prior이 다른 bounding box prior보다 더 많은 것에 의해 ground truth object가 오버랩한다면! 예를 들어(prior 1), 이전의 다른 bounding box보다 더 많이 첫번째 ground truth object보다 겹치고, prior2가 두번째 ground truth object와 겹친다. 시스템은 각 ground truth object에 대해 하나의 bounding box만 우선 할당한다. bounding box prior이 ground truth object에 할당되지 않은 경우 좌표 또는 클래스 예측에 대한 손실은 발생되지 않으며 오직 objectness만 발생한다. 만약 box가 가장 높은 IOU를 가지진 않지만 thresold 값 이상으로 ground truth object와 더 많이 겹치면 우리는 예측을 무시해도된다. (이때, thresold값 0.5) 5-2. Multi labels predection Open Image dataset과 같이 몇몇의 데이터셋들은 여러개의 label을 가질 수도 있다. 예를 들어, 하나의 object는 woman, person으로 label될 수 있다. 이 데이터셋에서, 많은 overlapping label이 존재한다. 클래스 예측에 대한 softmax를 사용하는 것은 각 box가 정확하게 하나의 class만 가진다는 가정을 두는 것이고, 그리고 그것은 종종 그렇지 않다. 이런 이유로 YOLOv3는 softmax를 사용하지 않는다. 대신 모든 class에 대해 독립적인 logistic classifier을 사용한다. 훈련 중에 class 예측을 위해 binary cross-entropy loss를 사용한다. 독립적인 logistic classifier를 사용하면, 한 object가 동시에 person으로서 woman으로서 detect될수 있다. 5-3. Small Objects Detection YOLO는 작은 object에 문제가 있었다. 그러나 YOLOv3는 작은 object에 더 나은 성능을 보인다. 왜냐하면 short cut connection을 사용하기 때문이다! short cut connetion 방법을 사용하는 것은 earlier feature map으로 부터 finer-grained information을 얻을 수 있다. 그러나 이전의 버전과 비교해서, YOLOv3는 medium과 large 사이즈 object에 대해 좀 더 안좋은 성능을 가지고 있다. 5-4. Feature Extractor Network(Darknet-53) YOLOv3는 feature extraction을 수행하는데 새로운 네트워크를 사용한다. YOLOv2(Darknet-19)에서 사용된 네트워크와 residual 네트워크 사이의 하이브리드 접근법이다. 그래서 몇몇의 short cut connection을 가진다. 53개 컨벌루션 레이어들을 가진다. 그것을 Darknet-53라 부른다. Darknet-53은 최신식의 classifier와 동등한 성능을 제공하지만 floating 작업이 적고 속도도 더 빠르다. classification 훈련후에 완전이 연결된 레이어는 Darknet-53으로 부터 제거되었다. 5-5. Predictions Across Scales YOLO와 YOLOv2와 다르게, 마지막 레이어에서 output을 예측한다. YOLOv3는 아래의 이미지에서 3개의 다른 규모들인 box들을 예측한다. 이것은 네트워크에 대한 간단한 diagram이다. 각각의 scale YOLOv3는 3개의 anchor box들을 사용하고 어떤 grid cell에 대해 3개의 box들을 예측한다. 각 object는 여전히 하나의 detection tensor에서 하나의 grid에 할당되어진다. 5-6. Performance AP50에서 정확도 vs 속도를 볼때, YOLOv3는 다른 detection 시스템을 넘어 상당한 benefit을 가진다. 그러나, YOLOv3 성능은 IOU threshold 증가함에 따라 떨어진다. YOLOv3는 object와 box를 완벽하게 분리하지는 못하지만, 그래도 다른 방법들보다는 빠르다.","categories":[],"tags":[{"name":"DL","slug":"DL","permalink":"https://kjm94.github.io/tags/DL/"}]},{"title":"loss","slug":"loss","date":"2021-05-31T01:50:39.000Z","updated":"2021-06-04T17:32:39.734Z","comments":true,"path":"2021/05/31/loss/","link":"","permalink":"https://kjm94.github.io/2021/05/31/loss/","excerpt":"","text":"손실함수(loss)모델을 훈련시킬때 이 손실 함수를 최소로 만들어주는 가중치들을 찾는 것을 목표 MSE(mean squared error) MAE(mean absolute error) hinge categorical crossentropy sparse categorical crossentropy binary crossentropy 훈련시키는 모델에 적합한 손실함수를 선택 loss: 손실함수. 훈련셋과 연관. 훈련에 사용.","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"Team_Project_No.2","slug":"Team-Project-No-2","date":"2021-05-19T15:07:54.000Z","updated":"2021-06-04T17:32:39.718Z","comments":true,"path":"2021/05/20/Team-Project-No-2/","link":"","permalink":"https://kjm94.github.io/2021/05/20/Team-Project-No-2/","excerpt":"","text":"Team_project 22. 한국 부동산 데이터 시각화 경진대회 언어 및 작업툴: Python, Tableau 인원: 3명 기간: 2021.04.21 - 2021.05.26 내용한국의 부동산 데이터와 사용자가 직접 수집한 외부 데이터를 활용하여 부동산 가격 변화 및 사회와의 관련성을 분석 기여: 준공실적, 분양실적 이중축 라인, 막대 그래프 시각화 결과:","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"Team_Project_No.1","slug":"Team-Project-No-1","date":"2021-05-13T00:04:45.000Z","updated":"2021-05-19T15:06:58.312Z","comments":true,"path":"2021/05/13/Team-Project-No-1/","link":"","permalink":"https://kjm94.github.io/2021/05/13/Team-Project-No-1/","excerpt":"","text":"Team_project 11. Tabular Playground Series - Apr 2021 언어 및 작업툴: Python 인원: 3명 기간: 2021.04.19 - 2021.05.01 내용가공된 타이타닉 생존자 데이터를 사용하여 해당 데이터에 맞는 생존자 예측하기 기여: 여러 modeling 학습 결과: 상위 28% https://github.com/KJM94/Team_project/blob/main/ppt/titanic_TeamProj_final-.pdf","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"Bayesian Optimization","slug":"Bayesian-Optimization","date":"2021-04-29T02:34:54.000Z","updated":"2021-05-19T15:06:58.308Z","comments":true,"path":"2021/04/29/Bayesian-Optimization/","link":"","permalink":"https://kjm94.github.io/2021/04/29/Bayesian-Optimization/","excerpt":"","text":"베이지안 최적화 불필요한 하이퍼 파라미터 반복 탐색을 줄여 빠르게 최적의 하이퍼 파라미터를 찾을 수 있는 방법 하이퍼 파라미터를 선택하는 문제에 대하여 정형화된 방법을 찾지 못해, 경험에 의해서 선택해야 함 사용하는 이유 그리드 서치 or 랜덤 서치는 도출된 하이퍼 파라미터 값을 일일이 모델에 적용한 뒤 성능 비교를 해야 하는 부분이 존재하지만 베이지안 최적화는 사용자가 설정한 파라미터 구간내에서 최적의 값을 도출함 베이지안 최적화에 사용되는 핵심 모듈 Surrogate model 확보된 데이터와 평가지표의 숨겨진 관계를 모델링 Acquisition function Surrogate model을 활용해 다음 탐색할 지점을 결정 베이지안 최적화는 사전에 정의된 하이퍼파라미터 집합으로부터 일반화 성능을 도출하는 surrogate model과 acquisition function을 사용하여 최적의 조합 결정 베이지안 최적화 과정 123456789101112lgb_params = &#123; &#x27;num_leaves&#x27;: (2, 50), &#x27;colsample_bytree&#x27;:(0.1, 1), &#x27;subsample&#x27;: (0.1, 1), &#x27;max_depth&#x27;: (1, 50), &#x27;reg_alpha&#x27;: (0, 0.5), &#x27;reg_lambda&#x27;: (0, 0.5), &#x27;min_split_gain&#x27;: (0.001, 0.1), &#x27;min_child_weight&#x27;:(0, 50), &#x27;subsample_freq&#x27;: (2, 50), &#x27;max_bin&#x27;: (5,200),&#125; 일정량의 hyperparameter 세팅을 X 변수로 하고 123456789101112131415161718192021def lgb_roc_eval(num_leaves, colsample_bytree, subsample, max_depth, reg_alpha, reg_lambda, min_split_gain, min_child_weight, subsample_freq, max_bin): params = &#123; &#x27;learning_rate&#x27;:0.01, &#x27;num_leaves&#x27;: int(round(num_leaves)), # 호출 시 실수형 값이 들어오므로 정수형 하이퍼 파라미터는 정수형으로 변경 &#x27;colsample_bytree&#x27;: colsample_bytree, &#x27;subsample&#x27;: subsample, &#x27;max_depth&#x27;: int(round(max_depth)), &#x27;reg_alpha&#x27;: reg_alpha, &#x27;reg_lambda&#x27;: reg_lambda, &#x27;min_split_gain&#x27;: min_split_gain, &#x27;min_child_weight&#x27;: min_child_weight, &#x27;subsample_freq&#x27;: int(round(subsample_freq)), &#x27;max_bin&#x27;: int(round(max_bin)), &#125; lgb_model = LGBMClassifier(**params) lgb_model.fit(bayes_x, bayes_y, eval_set=[(bayes_x_test, bayes_y_test)], early_stopping_rounds=100, eval_metric=&quot;auc&quot;, verbose=False) valid_proba = lgb_model.predict_proba(bayes_x_test, num_iteration=10)[:,1] roc_preds = roc_auc_score(bayes_y_test, valid_proba) return roc_preds 모델의 성능을 Y변수로 하여 데이터 셋을 만든다 1BO_lgb = BayesianOptimization(lgb_roc_eval, lgb_params, random_state=2121) 1234BO_lgb.maximize(init_points=5, n_iter=10)BO_lgb.max 1234567891011121314151617181920212223242526272829| iter | target | colsam... | max_bin | max_depth | min_ch... | min_sp... | num_le... | reg_alpha | reg_la... | subsample | subsam... |-------------------------------------------------------------------------------------------------------------------------------------------------| 1 | 0.8342 | 0.329 | 196.3 | 41.25 | 45.29 | 0.06231 | 28.93 | 0.1433 | 0.4287 | 0.3861 | 46.96 || 2 | 0.838 | 0.6284 | 15.83 | 39.32 | 44.95 | 0.04359 | 24.72 | 0.4127 | 0.000694 | 0.7192 | 13.98 || 3 | 0.8338 | 0.3291 | 72.7 | 38.96 | 25.69 | 0.06552 | 20.02 | 0.03046 | 0.3621 | 0.54 | 12.71 || 4 | 0.8277 | 0.2622 | 34.52 | 13.99 | 3.131 | 0.0492 | 11.02 | 0.1738 | 0.4319 | 0.308 | 17.25 || 5 | 0.8271 | 0.4439 | 138.9 | 9.848 | 48.94 | 0.02053 | 14.95 | 0.4408 | 0.213 | 0.8062 | 14.36 || 6 | 0.8363 | 0.6169 | 74.36 | 36.76 | 28.7 | 0.07251 | 19.8 | 0.2751 | 0.05854 | 0.3577 | 13.47 || 7 | 0.761 | 0.1915 | 13.88 | 33.33 | 44.99 | 0.06156 | 29.77 | 0.3761 | 0.4008 | 0.801 | 8.465 || 8 | 0.8006 | 0.1517 | 72.77 | 32.76 | 25.55 | 0.05765 | 22.96 | 0.03691 | 0.3594 | 0.9731 | 14.69 || 9 | 0.8348 | 0.9296 | 74.38 | 40.81 | 29.16 | 0.024 | 16.55 | 0.3314 | 0.1303 | 0.75 | 15.69 || 10 | 0.8271 | 0.4366 | 17.04 | 39.74 | 46.38 | 0.09246 | 23.49 | 0.1639 | 0.09529 | 0.518 | 19.89 || 11 | 0.8382 | 0.5201 | 16.37 | 39.06 | 48.15 | 0.05973 | 19.88 | 0.3476 | 0.06915 | 0.6018 | 13.36 || 12 | 0.7623 | 0.1818 | 75.99 | 41.25 | 32.32 | 0.04383 | 22.84 | 0.4678 | 0.4575 | 0.4314 | 12.78 || 13 | 0.8294 | 0.2367 | 15.62 | 40.93 | 41.88 | 0.09569 | 18.08 | 0.4144 | 0.2859 | 0.6626 | 11.77 || 14 | 0.7633 | 0.1896 | 197.7 | 41.72 | 41.81 | 0.0144 | 29.92 | 0.1247 | 0.1963 | 0.2601 | 43.21 || 15 | 0.8383 | 0.838 | 75.9 | 37.78 | 28.52 | 0.04416 | 15.26 | 0.3148 | 0.3394 | 0.736 | 14.43 |=================================================================================================================================================&#123;&#x27;target&#x27;: 0.8382516227577165, &#x27;params&#x27;: &#123;&#x27;colsample_bytree&#x27;: 0.8380432818402, &#x27;max_bin&#x27;: 75.89932895205534, &#x27;max_depth&#x27;: 37.77537008850686, &#x27;min_child_weight&#x27;: 28.524551188271897, &#x27;min_split_gain&#x27;: 0.04415839847288688, &#x27;num_leaves&#x27;: 15.259817309189941, &#x27;reg_alpha&#x27;: 0.31476726664722326, &#x27;reg_lambda&#x27;: 0.3394257380973246, &#x27;subsample&#x27;: 0.7360076401454746, &#x27;subsample_freq&#x27;: 14.425454096134617&#125;&#125; 해당 데이터셋에서 X와 Y의 관계를 가지고 사전 지식을 만든 후 새로운 데이터(X변수, hyperparameter 조합)이 들어 왔을 때 일반화 성능이 우수하도록 하는 최적의 x를 찾아서 추가해주는 형식으로 진행 위의 프로세스에서 surrogate model과 acquistion function 등장하는데 surrogate model은 X변수를 입력받아 일반화 성능과 불확실성에 관련된 분포를 내뱉는 함수 Acquisition function은 가장 최적의 x값을 찾는 함수 장점 탐색 시간적인 측면에서 효율을 가질 수 있음 단점 hyperparameter가 증가하면 차원이 급격하게 늘어나 성능을 예측하는 것이 점점 어려움 참고자료 : https://www.kaggle.com/elon4773/titanic-visualization-bayesian-optimization","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"상자안의 텍스트","slug":"상자안의-텍스트","date":"2021-04-27T13:08:15.000Z","updated":"2021-04-27T13:09:35.680Z","comments":true,"path":"2021/04/27/상자안의-텍스트/","link":"","permalink":"https://kjm94.github.io/2021/04/27/%EC%83%81%EC%9E%90%EC%95%88%EC%9D%98-%ED%85%8D%EC%8A%A4%ED%8A%B8/","excerpt":"","text":"상자 안의 텍스트출력 입력받은 수 만큼 양 옆의 공백을 만든 뒤 *로 텍스트를 감싼다. 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;#include &lt;string&gt;using namespace std;int main()&#123; cout &lt;&lt; &quot;문자열 입력 : &quot;; string name; cin &gt;&gt; name; cout &lt;&lt; &quot;공백의 수 : &quot;; int padding; cin &gt;&gt; padding; const string hi = &quot;Hello, &quot; + name + &quot;!!!&quot;; int rows = padding * 2 + 3; const string hi_space(hi.size(), &#x27; &#x27;); const string padding_space(padding, &#x27; &#x27;); const string space_line = &quot;*&quot; + padding_space + hi_space + padding_space + &quot;*&quot;; const string hi_line = &quot;*&quot; + padding_space + hi + padding_space + &quot;*&quot;; const string aster(hi_line.size(), &#x27;*&#x27;); for (int i = 0; i &lt; rows; i++) &#123; if (i == 0 || i == rows - 1) &#123; cout &lt;&lt; aster &lt;&lt; endl; &#125; else if (i == padding + 1) &#123; cout &lt;&lt; hi_line &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; space_line &lt;&lt; endl; &#125; &#125; return 0;&#125;","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://kjm94.github.io/tags/C/"}]},{"title":"다중 분류","slug":"다중-분류","date":"2021-04-24T03:30:48.000Z","updated":"2021-04-25T03:57:52.722Z","comments":true,"path":"2021/04/24/다중-분류/","link":"","permalink":"https://kjm94.github.io/2021/04/24/%EB%8B%A4%EC%A4%91-%EB%B6%84%EB%A5%98/","excerpt":"","text":"다중 분류 둘 이상의 클래스를 분류하는 것 다중 분류기를 구현하는 기법으로는 SGD 분류기, 랜덤 포레스트 분류기, 나이브 베이즈분류기 같은 알고리즘으로 여러 개의 클래스를 직접 처리하거나, 이진 분류기(로지스틱 회귀, 서포트 벡터 머신 분류기 등)을 여러 개 사용해 다중 클래스를 분류하는 방법이 있다 이진 분류기를 여러개를 사용하여 다중 클래스를 분류할 수 있음 두가지 접근법 One-vs-Rest( One vs All) One-vs-One One vs Rest(One vs All) 결정 점수 중에서 가장 높은 것을 클래스로 선택하여 이미지를 이진 분류기들로만 구성한 것 0~9까지(10개) 분류기를 학습시켜 각 분류기의 결정 점수 중 가장 높은 값을 결정 N개 분류기 모델은 N개 분류에 대해 훈련된다. 가장 높은 예측 확률을 가진 분류가 최종 출력으로 예측된다 대부분의 이진 분류 알고리즘에서 선호 One vs One 0과 1 구별, 0과 2 구별 등 각 숫자의 조합마다 이진 분류기를 훈련시키는 것 N * (N-1)개 분류기 모델은 각 분류 쌍에 대해 훈련된다 서포트 벡터 머신(SVM)과 같은 일부 알고리즘은 훈련 세트의 크기에 민감해서 큰 훈련 세트에서 몇 개의 분류기를 훈련시키는 것보다 작은 훈련 세트에서 많은 분류기를 훈련시키는 쪽이 빠르므로 ovo를 선호 각 분류기의 훈련에 전체 훈련 세트 중 구별 할 두 클래스에 해당하는 샘플만 필요 불균형 데이터 남/여, 구매여부 등 클래스 분포를 예측해야 하는 분류문제에서 예측 라벨 값의 분포가 100:1, 200:1 등으로 불균형하게 나타나는 상태 불균형 데이터로 인한 발생 문제 과적합 문제 발생 과적합은 변수가 많아서 생기는 모델 복잡성 증가, 데이터 불균형으로 생기는 문제 등의 다양한 발생 원인들이 존재 정확도는 높아질 수 있지만 분포가 작은 값에 대한 정밀도는 낮을 수 있고, 분포가 작은 클래스의 재현율이 낮아지는 문제가 발생할 수 있다. Ex) 분포가 100개의 데이터에서 1과 0값이 각각 97:3 비율을 가지고 있을 때 모든 값을 1로 예측한다 하더라도 정확도가 97% 나오게 된다. Under Sampling Down Sampling이라고도 불리며 데이터의 분포가 높은 값을 낮은 값으로 맞춰주는 작업을 거치는 것 유의미한 데이터만을 남길 수 있음 정보가 유실되는 문제가 생길 수 있음 Over Sampling Up Sampling이라고도 불리며 분포가 작은 클래스의 값을 분포가 큰 클래스로 맞춰주는 샘플링 방법 정보의 손실을 막을 수 있다 여러 유형의 관측치를 다수 추가하기 때문에 오히려 오버피팅을 야기할 수 있다 Log loss 로그 손실은 잘못된 분류에 패널티를 적용하여 모델의 정확도를 향상 모델 성능 평가 시 사용 가능한 지표 확률 값을 평가 지표로 사용 일반적으로 로그 손실이 낮을수록 정확도가 높아짐 잘못 예측할 수록, 페널티를 부여하기 위해 확률 값을 음의 log함수에 넣어 변환 확률이 낮아질 수록 log loss 값이 기하급수적으로 증가 확률이 낮을 때 패널티를 더 많이 부여하기 위해 음의 로그 함수를 사용","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"회귀 평가","slug":"회귀-평가","date":"2021-04-22T12:53:34.000Z","updated":"2021-04-22T12:59:11.223Z","comments":true,"path":"2021/04/22/회귀-평가/","link":"","permalink":"https://kjm94.github.io/2021/04/22/%ED%9A%8C%EA%B7%80-%ED%8F%89%EA%B0%80/","excerpt":"","text":"회귀 평가회귀 평가 지표 실제 값과 예측값의 차이를 기반으로 함 MAE, MSE, RMSE, RMSLE는 값이 작을수록 회귀 성능이 좋은 것 값이 작을수록 예측값과 실제값의 차이가 없다는 것을 의미 MSE(Mean Squared Error) 실제 값과 예측 값의 차이를 제곱해 평균한 것 MAE(Mean Absolue Error) 실제 값과 예측 값의 차이를 절댓값으로 변환해 평균한 것 RMSE(Root Mean Squared Error) MSE 값은 오류의 제곱을 구하므로 실제 오류 평균보다 더 커지는 특성이 있어 MSE에 루트를 씌운 RMSE 값을 씀 RMSLE(Root Mean Squared Log Error) 오차(Error)를 제곱(Square)해서 평균(Mean)한 값의 제곱근(Root)으로 값이 작을 수록 정밀도가 높음 0에 가까운 값이 나올 수록 정밀도가 높은 값 과대평가 된 항목보다는 과소평가 된 항목에 패널티를 줌 RMSE와 비교해서 RMSLE가 가진 장점 아웃라이어에 강건함 RMSLE는 아웃라이어가 있더라도 값의 변동폭이 크지 않음 상대적 Error를 측정 RMSE와 달리 RMSLE는 예측값과 실제값의 상대적 Error를 측정 Under Estimation에 큰 패널티를 부여 과대 평가이던 과소 평가이던 간에 RMSE값은 동일함RMSLE는 Under Estimation일 때(즉, 예측값이 실제값보다 작을 때) 더 높은 패널티가 주어짐","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"성능 측정","slug":"성능-측정","date":"2021-04-17T06:40:38.000Z","updated":"2021-04-22T12:52:46.732Z","comments":true,"path":"2021/04/17/성능-측정/","link":"","permalink":"https://kjm94.github.io/2021/04/17/%EC%84%B1%EB%8A%A5-%EC%B8%A1%EC%A0%95/","excerpt":"","text":"성능 측정 정확도 혼동 행렬 정밀도 재현율 F1 Score ROC curve AUC 정확도(Accuracy) 전체 값 중에 올바르게 예측한 값이 몇 개인지 판단 직관적으로 모델 예측 성능을 나타내는 평가 지표 예측결과가 동일한 데이터 건수 / 전체 예측 데이터 건수 혼동 행렬(Confusion matrix) 모델의 성능을 평가할 때 사용되는 지표 예측 값이 실제 관측 값을 얼마나 정확하게 예측 했는지 보여주는 행렬 정밀도(Precision) 모델의 예측 값이 얼마나 정확하게 예측됐는가를 나타내는 지표 관측의 균질성 관측된 값의 편차가 적을수록 정밀 TP/TP+FP 재현율(recall) 실제 값 중에서 모델이 검출한 실제 값의 비율을 나타내는 지표 TP/TP+FN F1 Score 정밀도와 재현율 두 값을 조화 평균을 내서 하나의 수치로 나타낸 지표 2 * 재현율 * 정밀도/(재현율+정밀도) 정밀도/ 재현율 트레이드오프 정밀도와 재현율의 중요성은 사례마다 다름 임곗값(Threshold)를 조정하여 정밀도나 재현율의 수치 조정 임곗값이 높을수록 재현율을 낮아지고 정밀도는 높아짐 정밀도와 재현율은 서로 반비례 관계 ROC curve 임곗값(threshold)이 달라짐에 따라 분류모델의 성능이 어떻게 변하는지를 나타내는 곡선 임곗값의 변화에 따라 성능 평가 지표의 값이 어떻게 변하는지를 시각화한 곡선 분류 모델의 y값은 기본적으로 확률 값으로 출력 이를 분류 결과로 변환해 주기 위해서는 0과 1사이의 일정한 값을 기준으로 이보다 크면 참, 작으면 거짓으로 취급함 임곗값을 달리 취해주는 경우 일반적으로는 0.5를 기준으로 사용하지만, 참인 것을 반드시 잡아주어야 하는 경우 기준값 변경 환자가 코로나 바이러스와 같은 전염병에 걸렸는지 여부, 조금이라도 낌새가 있으면 모두 양성으로 처리해야 할 때를 예로 들 수 있음 False Negative를 최대한 피해 주어야 할 경우 임곗값을 0.1로 잡아준다던지, 그 반대의 경우로 최대한 참으로 판명하는 것을 보수적으로 결정해야 할 경우에는 0.9로 잡아 주는 등의 결정을 내려야함 기준 값을 낮추면 그에 따라 Positive 예측 확률이 증가하고 그에 따라서 재현율이 증가하게 되어 대상 물체를 빠뜨리지 않고 잘 잡아내게 됨 반대로 기준값을 높이면 정밀도가 증가하여 검출된 결과가 얼마나 정확한지 다시 말하여 검출 결과들 중 실제 물체가 얼마나 포함되어 있는지를 나타냄 분석가가 수용 가능한 False Positive Rate 정도를 결정해 주어야 함 AUCArea Under the Curve ROC 커브 하단 영역의 넓이를 구한 값 0~1 사이의 값을 갖는다 더 높을수록 더 좋은 분류 성능 판단이 불분명한 부분이 적을수록 이상적인 분류 성능을 보임","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"기초통계 자료","slug":"기초통계-자료","date":"2021-04-16T07:58:39.000Z","updated":"2021-04-17T06:39:54.436Z","comments":true,"path":"2021/04/16/기초통계-자료/","link":"","permalink":"https://kjm94.github.io/2021/04/16/%EA%B8%B0%EC%B4%88%ED%86%B5%EA%B3%84-%EC%9E%90%EB%A3%8C/","excerpt":"","text":"https://github.com/KJM94/R_prac/tree/main/2021_04_05_%EA%B8%B0%EC%B4%88%ED%86%B5%EA%B3%84%EB%B0%9C%ED%91%9C","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"로지스틱 회귀","slug":"로지스틱-회귀","date":"2021-04-16T07:44:44.000Z","updated":"2021-04-17T06:39:54.447Z","comments":true,"path":"2021/04/16/로지스틱-회귀/","link":"","permalink":"https://kjm94.github.io/2021/04/16/%EB%A1%9C%EC%A7%80%EC%8A%A4%ED%8B%B1-%ED%9A%8C%EA%B7%80/","excerpt":"","text":"로지스틱 회귀 분석 회귀를 사용하여 데이터가 어떤 범주에 속할 확률을 0에서 1사이의 값으로 예측하고 그 확률에 따라 가능성이 더 높은 범주에 속하는 것으로 분류해주는 지도 학습 알고리즘 독립변수와 종속변수의 관계를 찾음으로써, 새로운 독립변수의 집합이 주어졌을 때, 종속 변수의 값을 예측할 수 있음 이항 로지스틱 회귀와 다항 로지스틱 회귀 이항 로지스틱 회귀 -&gt; 범주가 두개인 결과 변수 예측 다항 로지스틱 회귀 -&gt; 2개보다 많은 결과 변수 예측 로지스틱 회귀 3가지 요소 Odds Logit 변환 시그모이드 함수 Odds 범주 0에 속할 확률 대비 범주 1에 속할 확률 Logit 변환 odds에 log를 앞에 붙인 형태를 Logit 변환이라고 함 Log를 붙이면 형태가 선형형태로 바뀌고 수식도 간단해짐 시그모이드 함수 확률을 0에서 1사이로 커브 모양으로 나타내야 하는데, 이걸 가능하게 해주는게 바로 Sigmoid 함수다. 시그모이드 함수는 결과 값을 0~1 사이의 값으로 변환해주는 역할만 한다. Odds를 Sigmoid 함수에 넣어서 0~1 사이 값으로 변환해준다. 로그 가능도 가정된 분포에서 주어진 데이터가 나올 확률 계산과 편의를 위해 일반적으로 가능도함수에 로그함수를 씌어 사용 GLM은 최소제곱법이 아닌 최대가능도추정법을 이용 이탈도 로지스틱 회귀모형이 얼마나 데이터를 못 설명하는지에 대한 척도 어떤 모형의 a의 최대로그우도에서 포화모형 b의 최대로그우도를 뺀 것에 -2를 곱한 것 카이제곱분포를 사용하기 때문에 이탈도 값의 유의성을 계산하기 쉽기 때문에 로그가능도 보다 더 많이 사용을 한다 이탈도가 낮을 수록 좋은 모형 AIC 입력변수의 수가 증가한다고 항상 작아지지는 않으므로 가장 작은 AIC를 가지는 모형을 선택 AIC 값은 낮을수록 좋다.","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"회귀분석","slug":"ii회귀분석","date":"2021-04-16T06:55:45.000Z","updated":"2021-04-17T06:39:54.429Z","comments":true,"path":"2021/04/16/ii회귀분석/","link":"","permalink":"https://kjm94.github.io/2021/04/16/ii%ED%9A%8C%EA%B7%80%EB%B6%84%EC%84%9D/","excerpt":"","text":"회귀분석 하나 이상의 독립변수들이 종속변수에 미치는 영향을 추정할 수 있는 통계 기법 변수들 사이의 인과관계를 밝히고 모형을 적합(fit)하여 관심 있는 변수를 예측하거나 추론하기 위한 분석 방법 독립 변수와 종속변수의 개수 및 특성에 따라 단순 회귀, 다중 회귀, 다항 회귀, 곡선 회귀, 로지스틱 회귀, 비선형 회귀로 분류 회귀분석의 요소 독립변수(x) : 영향을 주는 변수, 설명변수, 예측변수 종속변수(y) : 영향을 받는 변수, 반응변수, 결과변수 잔차 : 표본 집단에서 회귀식을 얻고, 그 회귀식을 통해 도출한 예측값과 실제값의 차이 회귀 계수의 추정 최소 제곱법 자료에 가장 잘 맞는 선을 찾는 방법.이 방법을 통해 최량 적합선을 찾는다. 관측된 자료점에서 이탈도가 가장 작은 직선그래프 측정값을 기초로 하여 제곱합을 만들고 그것을 최소로 하는 값을 구하여 측정결과를 처리하는 방법으로 오차 제곱의 합이 가장 작은 해를 구하는 것 적합도 검정모형이 자료에서 벗어난 정도로 표현 F-value : 여러 표본 간 차이의 회귀성과 유의성을 나타내는 통계적 지표. 회귀식의 설명력에 대한 수치이다. 회귀 분석의 종류 단순 회귀 : 독립변수가 1개이며, 종속변수와의 관계가 직선 다중 회귀 : 독립변수가 k개이며, 종속변수와의 관계가 선형(1차 함수) 다항 회귀 : 독립변수와 종속변수와의 관계가 1차 함수 이상인 단계(단, 독립변수가 1개일 경우에는 2차 함수 이상) 곡선 회귀 : 독립변수가 1개이며 종속변수와의 관계가 곡선 로지스틱 회귀 종속변수가 범주형(2진 변수)인 경우 적용 단순 로지스틱 회귀 및 다중, 다항 로지스틱 회귀로 확장 가능 비선형 회귀 : 회귀식 모양이 선형관계로 이뤄져 있지 않은 모형 다중 회귀분석 두개 이상의 독립 변수들과 하나의 종속 변수의 관계를 분석하는 기법으로 단순 회귀 분석을 확장한 것. 단순회귀분석보다는 추가적인 독립변수를 도입함으로써 오차항의 값을 줄여 분석 내용을 향상시킬 수 있다. 회귀 모형에서 독립변수가 추가된다는 것은 분석 그래프의 차원이 증가함을 의미하기 때문에 3차원 이상의 그래프이다. 독립변수들의 선형적 결합으로 종속변수를 예측하는 통계기법 다중 회귀식의 추정 방법 동시 입력 연구자가 고려하는 모든 독립변수들을 한꺼번에 넣고 분석하는 방법 다른 독립변수들이 통제된 상태에서 특정 독립변수의 영향력을 알 수 있음. 연구자가 고려하는 모든 독립변수들이 동시에 종속 변수를 설명하는 정도를 나타냄. 단계적 입력 다른 변수들이 회귀식에 존재할 때 종속변수에 영향력이 있는 변수들만을 회귀식에 포함시키는 방식 설명력이 높은 변수의 순으로 회귀식에 포함 전 단계에서 회귀식에 포함된 독립 변수들도 나중에 들어오는 변수 때문에 설명력이 매우 낮아지면 회귀식에서 제거 종속 변수를 설명하는 데에 있어서 설명력이 어느정도 이상되는 변수들로만 구성된 회귀식을 발견하는데에 유용하다. 후진 모든 독립 변수를 모두 포함한 상태에서 기여도가 적은 변수부터 하나씩 빼기 시작한다. 모델에 남아있는 변수들의 p-value가 유의수준 이하가 될 때까지 삭제하는 방법 전진 독립 변수가 하나도 포함되지 않은 모델로부터 출발한다. F값에 가장 큰 기여를 하는 변수를 순서대로 하나씩 더해가는 방법 다중 회귀 분석의 최소제곱법 모집단에 대한 기본 가정들이 충족된다는 가정하에, 최소제곱법을 이용하여 표본회귀선을 도출할 수 있다. 다중 회귀 분석의 적합도 아카이케 정보기준(AIC) 모형에 변수를 추가할수록 R제곱이 점점 커지는 점을 보완하기 위해 나온 개념. 모형에 예측 변수가 많을수록 벌점을 준다는 특징이 있다. 회귀 모형의 전제 회귀 분석은 회귀선을 그리는게 전부가 아니다. 이 데이터가 신뢰할 수 있는 모형인지, 회귀분석에 적합한 데이터인지 확인하는 과정이 필수적이다. 회귀분석을 하려면 데이터가 선형성, 독립성, 등분산성, 정상성의 가정을 만족시킬 수 있어야한다. 회귀 모형의 가정 선형성 독립변수의 각 수준에서 종속변수의 분포의 평균은 직선상에 위치한다. 즉, 회귀 모형은 종속변수와 독립변수들이 선형적 관계를 갖는다고 가정될 수 있을 때 사용된다. 선형적이란 말은 독립변수의 변화에 따라 종속변수도 일정 크기로 변화한다는 뜻이다. 잔차의 산점도를 통하여 선형성을 파악한다. 독립성 종속변수들은 통계적으로 독립적이어야 한다. 독립변수 x와 오차항이 통계적으로 상호 독립적이며, 잔차는 자기상관이 없어야 한다. 잔차의 산점도를 통하여 잔차들이 일정한 경향성 없이 일정하게 분포되었는지 확인하기 위해서, 통계량으로는 더빗 왓슨 검정 실시한다. 등분산성 독립변수의 모든 값에 대해 오차들의 분산이 일정해야 한다. 정상성 잔차항이 정규 분포를 이뤄야 한다. 샤피로-월크 검정, 콜모고로프-스미르노프 적합성 검정을 이용하여 검정한다. 주로, 시각화를 통한 검정 기법으로 Q-Q plot을 사용한다. 회귀 모형의 전제 다중 공선성 모형의 일부 예측변수가 다른 예측변수와 상관되어 있을 때 발생하는 조건이다. 통계의 가정과는 관계없지만 다중회귀 결과를 해석할 때 중요하다. 중대한 다중공산성은 회귀계수의 분산을 증가시켜 불안정하고 해석이 어렵게 만들어 문제가 된다. 중대한 다중공산성 문제를 해결하기 위해 높은 상관 관계가 있는 예측변수를 모형에서 제거하는 방법을 사용한다. 이러한 다중공산성을 알아내기 위해 F 검정을 사용한다. 회귀 모형 종류에 따른 가정 검증 단순선형 회귀 분석 독립변수와 종속변수 간의 선형성 검증 선형성 검증을 위해 산점도 활용 다중선형 회귀 분석 회귀 모형 가정인 선형성, 독립성, 등분산성, 정상성, 다중공산성을 모두 만족하는지 검증 회귀 모형 검증 F 통계량 확인. 유의수준 5%이하에서 F-통계량의 p-값이 0.05보다 작으면 추정된 회귀식은 통계적으로 유의 해당 계수의 T-통계량과 p-값 또는 이들의 신뢰구간 확인 잔차를 그래프로 그리고 회귀진단을 한다. 선형성, 독립성, 등분산성, 비상관성, 정상성 가정을 만족시켜야 함 결정계수를 확인, 결정계수는 0~1을 가지며, 높은 값을 가질수록 추정된 회귀식의 설명력이 높다. 회귀 직선의 적합도 검토 및 모형의 통계적 유의성 회귀 직선의 적합도 검토 결정계수를 통해 추정된 회귀식이 얼마나 타당한지 검토한다. 결정계수가 1에 가까울수록 회귀 모형이 자료를 잘 설명한 것이다. 이것으로 독립변수가 종속변수 변동의 몇 %를 설명하는지 알 수 있다. 다변량 회귀 분석에서는 독립변수의 수가 많아지면 결정계수가 높아지므로 독립변수가 유의하든, 유의하지 않든 독립변수의 수가 많아지면 결정계수가 높아지는 단점이 있음. -&gt; AIC로 보완 모형의 통계적 유의성 모형의 통계적 유의성은 F-통계량으로 확인할 수 있다. 유의수준 5%이하에서 F-통계량의 p-값이 0.05보다 작으면 추정된 회귀식은 통계적으로 유의하다고 볼 수 있다. F-통계량이 크면 p-값이 0.05보다 작아지고 이렇게 되면 귀무가설을 기각하므로 모형이 유의하다고 결론 지을 수 있다.","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"상관분석","slug":"상관분석","date":"2021-04-16T06:51:55.000Z","updated":"2021-04-17T06:39:54.450Z","comments":true,"path":"2021/04/16/상관분석/","link":"","permalink":"https://kjm94.github.io/2021/04/16/%EC%83%81%EA%B4%80%EB%B6%84%EC%84%9D/","excerpt":"","text":"상관분석 연속 변수로 측정된 두 변수간의 선형 관계를 분석하는 기법 두 변수 중 적어도 하나의 변수는 정규분포일 것 연속형 두 변수 간에는 선형적인 관계일 것 공분산 2개의 확률 변수의 상관 정도를 나타내는 값 만약 하나의 값이 상승하는 경향을 보이면서 다른 값도 상승 -&gt; 공분산 값은 양수, 반대면 음수를 보임 공분산 값만으로는 상승, 하강 경향을 알 수는 있으나 어느정도의 상관관계인지는 알 수 없음 -&gt; 따라서 공분산을 표준화 시킨 “상관계수”를 통해 파악 피어슨 상관계수 두 변수의 선형적인 관계 정도를 나타냄 일반적으로 피어슨 상관계수를 의미","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"두 평균의 비교","slug":"두-평균의-비교","date":"2021-04-16T06:08:58.000Z","updated":"2021-04-17T06:39:54.443Z","comments":true,"path":"2021/04/16/두-평균의-비교/","link":"","permalink":"https://kjm94.github.io/2021/04/16/%EB%91%90-%ED%8F%89%EA%B7%A0%EC%9D%98-%EB%B9%84%EA%B5%90/","excerpt":"","text":"두 평균의 비교T 검정과 T분포 T검정의 정의 T검정은 모집단의 분산이나 표준편차를 알지 못할 때, 모집단에서 얻은 표본으로부터 추정된 분산이나 추정된 표준편차를 가지고 T분포에 의거하여 검정하는 방법 T분포 자유도에 따라 형태가 달라지는 가족분포이며 평균이 0이고 좌우대칭의 분포인 정규분포이고 표준편차가 1보다 큰 분포 자유도에 따른 T분포의 형태는 자유도의 값이 커질수록 즉 무한루프에 가까우면 T분포는 표준정규분포 즉 Z분포에 가까워지게 됨 단일표본 T검정 모집단의 분산을 알지 못할 때, 모집단에서 추출된 표본의 평균과 연구자가 이론적, 경험적 배경으로 설정한 수를 비교 검정하는 방법 독립표본 T 검정 각기 다른 두 모집단의 속성인 평균을 비교하기 위하여 두 모집단으로부터 표본들을 각각 독립적으로 추출한 후, 각 표본의 평균들을 비교해서 모집단의 유사성을 검정하는 방법. 대응표본 T검정 알지 못하는 각기 다른 두 모집단의 속성인 평균을 비교하기 위하여 두 모집단으로부터 표본들을 추출하여 표본의 평균들을 비교함으로써 모집단의 평균을 비교하는 통계적 방법.","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"가설 설정","slug":"기초통계","date":"2021-04-16T05:31:11.000Z","updated":"2021-04-17T06:39:54.440Z","comments":true,"path":"2021/04/16/기초통계/","link":"","permalink":"https://kjm94.github.io/2021/04/16/%EA%B8%B0%EC%B4%88%ED%86%B5%EA%B3%84/","excerpt":"","text":"가설 설정모집단과 표본 설정 모집단 : 특성을 알고 하는, 연구의 대상이 되는 모든 개체들의 전체 집합 모수 : 모집단의 특성을 나타내는 값 표본 : 연구를 위해서 모집단에서 추출된 일부 값 통계량 : 표본의 특성을 나타내는 결과치 가설의 설정 어떤 사실이나 현상에 대한 법칙이나 결과를 얻어내기 위해 연구 모델을 설계하는 과정 중 하나 검정하고자 하는 모수에 대하여 귀무가설과 대립가설로 설정한다. 가설검정 모집단의 특성에 대한 통계적 가설을 모집단으로부터 추출한 표본을 사용하여 검토하는 통계적 추론 통계적 유의성을 검정하는 것 가설검정의 절차통계적 가설 검정 절차는 5가지의 절차를 거칩니다. 유의수준의 결정, 귀무가설과 대립가설 설정 검정통계량 설정 기각역의 설정 검정통계량 계산 통계적인의사결정 가설검정에 대한 예 어느 과자제품의 용량표기에 200g이라 표기되어 있는데 질소 없이 순수하게 200g인가? 새로 개발한 전자제품이 과거의 같은 라인의 제품보다 전성비가 좋은 것이 사실인가? 가설에 대한 답을 주는 것이 가설검정이다.표본을 통해 모집단 모수에 대한 두 가지 가설을 놓고 통계적 의사결정 귀무가설 모집단과 Sample의 평균은 같다. 비교하는 값과 차이가 없다는 것을 기본개념으로 하는 가설. 대립가설 모집단과 Sample의 평균은 다르다. 뚜렷한 증거가 있을 때 주장하고자 하는 가설로 차이가 있다는 것이 기본개념. 양측 가설과 단측 가설로 나눌 수 있다. 양측가설과 검정 모수 값이, 귀무가설에서 지정한 값보다 크거나 작을 수 있는 가설 단측가설과 검정 이전 데이터와 비교해 달라진 점 모수값이, 귀무가설에서 지정한 값보다 크다 혹은 작다 처럼 한쪽 방항으로만 진술되는 가설 단측검정주제 : 카페에서 파는 커피용량이 200ml보다 적다. 귀무가설 : 커피의 용량은 200ml 대립가설 : 커피의 용량은 200ml보다 적다. 오류 제 1종의 오류 : 귀무가설이 옳은데도 기각하게 되는 오류. 제 2종의 오류 : 귀무가설이 옳지 않은데도 채택하는 오류. 제 1종의 오류 확률의 최대 허용치를 미리 특정값으로 지정해놓고 제 2종의 오류의 확률을 가장 작게 하는 검정 방법이 일반적 검정통계량과 기각역 검정통계량 : 관찰된 표본으로부터 구하는 통계량으로 분포가 가설에서 주어지는 모수에 의존한다. 가설의 진위를 판단하는 수단 기각역 : 검정통계량의 분포에서 유의수준 a의 크기에 해당하는 영역으로 계산된 검정통계량의 유의성을 판정하는 기준이 된다. 유의수준(a) 결정 유의수준 : 표본평균이 모평균과 같은데, 표본평균이 모평균과 다르다라고 선택하는 오류를 범할 허용한계 0.01 -&gt; 의료계통 0.05 -&gt; 논문 0.10 -&gt; 사회과학 등 신뢰도 : 검정하려는 귀무가설이 참인 경우, 이를 옳다고 판단하는 확률 유의확률 p-Value : 귀무가설이 맞다고 가정할 때 얻은 결과보다 극단적인 결과가 실제로 관측될 확률","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"classification","slug":"classification","date":"2021-04-13T07:58:58.000Z","updated":"2021-05-19T15:06:58.316Z","comments":true,"path":"2021/04/13/classification/","link":"","permalink":"https://kjm94.github.io/2021/04/13/classification/","excerpt":"","text":"설정 matplotlib 그래프를 인라인으로 출력 그림을 저장하는 함수 12345678910111213141516171819202122232425262728293031323334353637383940# 파이썬 ≥3.5 필수import sysassert sys.version_info &gt;= (3, 5)# 사이킷런 ≥0.20 필수import sklearnassert sklearn.__version__ &gt;= &quot;0.20&quot;# 공통 모듈 임포트import numpy as npimport os# 노트북 실행 결과를 동일하게 유지하기 위해np.random.seed(42)# 깔끔한 그래프 출력을 위해% matplotlibinlineimport matplotlib as mplimport matplotlib.pyplot as pltmpl.rc(&#x27;axes&#x27;, labelsize=14)mpl.rc(&#x27;xtick&#x27;, labelsize=12)mpl.rc(&#x27;ytick&#x27;, labelsize=12)# 그림을 저장할 위치PROJECT_ROOT_DIR = &quot;../../../classification&quot;CHAPTER_ID = &quot;classification&quot;IMAGES_PATH = os.path.join(PROJECT_ROOT_DIR, &quot;images&quot;, CHAPTER_ID)os.makedirs(IMAGES_PATH, exist_ok=True)def save_fig(fig_id, tight_layout=True, fig_extension=&quot;png&quot;, resolution=300): path = os.path.join(IMAGES_PATH, fig_id + &quot;.&quot; + fig_extension) print(&quot;그림 저장:&quot;, fig_id) if tight_layout: plt.tight_layout() plt.savefig(path, format=fig_extension, dpi=resolution) MNIST 손으로 쓴 7만개의 숫자 이미지를 모은 데이터셋 MNIST 데이터셋 내려받는 코드 123from sklearn.datasets import fetch_openmlmnist = fetch_openml(&#x27;mnist_784&#x27;, version=1, as_frame=False)mnist.keys() dict_keys([&#39;data&#39;, &#39;target&#39;, &#39;frame&#39;, &#39;feature_names&#39;, &#39;target_names&#39;, &#39;DESCR&#39;, &#39;details&#39;, &#39;categories&#39;, &#39;url&#39;]) 사이킷런에서 읽어 들인 데이터셋들은 딕셔너리 구조를 갖고 있음. 데이터셋을 설명하는 DESCR 키 샘플이 하나의 행, 특성이 하나의 열로 구성된 배열을 가진 data 키 레이블 배열을 담은 target 키 12X, y = mnist[&quot;data&quot;], mnist[&quot;target&quot;]X.shape (70000, 784) 이미지가 7만개 있고 각 784개의 특성을 갖고 있음.이미지가 28 x 28 픽셀이기 때문특성은 0~255까지의 픽셀 강도를 나타냄. 이미지 한개 확인하기 샘플의 특성 벡터를 추출해서 28 x 28 배열로 크기를 바꾸고 matplotlib의 imshow() 함수를 사용 1y.shape (70000,) 128 * 28 784 1234567891011%matplotlib inlineimport matplotlib as mplimport matplotlib.pyplot as pltsome_digit = X[0]some_digit_image = some_digit.reshape(28, 28)plt.imshow(some_digit_image, cmap=mpl.cm.binary)plt.axis(&quot;off&quot;)save_fig(&quot;some_digit_plot&quot;)plt.show() 그림 저장: some_digit_plot 숫자 5 이미지의 실제 레이블 1y[0] &#39;5&#39; 레이블은 문자열이며, 머신러닝 알고리즘은 숫자 인식이 필요하기 때문에 y를 정수로 변환함. 1y = y.astype(np.uint8) 12345def plot_digit(data): image = data.reshape(28, 28) plt.imshow(image, cmap = mpl.cm.binary, interpolation=&quot;nearest&quot;) plt.axis(&quot;off&quot;) 123456789101112131415# 숫자 그림을 위한 함수def plot_digits(instances, images_per_row=10, **options): size = 28 images_per_row = min(len(instances), images_per_row) images = [instance.reshape(size,size) for instance in instances] n_rows = (len(instances) - 1) // images_per_row + 1 row_images = [] n_empty = n_rows * images_per_row - len(instances) images.append(np.zeros((size, size * n_empty))) for row in range(n_rows): rimages = images[row * images_per_row : (row + 1) * images_per_row] row_images.append(np.concatenate(rimages, axis=1)) image = np.concatenate(row_images, axis=0) plt.imshow(image, cmap = mpl.cm.binary, **options) plt.axis(&quot;off&quot;) 12345plt.figure(figsize=(9,9))example_images = X[:100]plot_digits(example_images, images_per_row=10)save_fig(&quot;more_digits_plot&quot;)plt.show() 그림 저장: more_digits_plot 1y[0] 5 1X_train, X_test, y_train, y_test = X[:60000],X[60000:],y[:60000],y[60000:] 이진 분류기ex) 숫자 5만 식별하기5와 5가 아닌 것 두개의 클래스를 구분 하는 것 타깃 벡터 만들기 12y_train_5 = (y_train == 5)y_test_5 = (y_test == 5) max_iter와 tol 같은 일부 매개변수는 사이킷런 다음 버전에서 기본값이 바뀝니다. 버전이 업데이트 되더라도 결과가 바뀌지 않도록 아예 나중에 바뀔 기본값을 사용해 명시적으로 지정합니다. 확률적 경사 하강법Stochastic Gradient Descent (SGD) 매우 큰 데이터셋을 효율적으로 처리하는 방법 한 번에 하나씩 훈련 샘플을 독립적으로 처리함. 1234from sklearn.linear_model import SGDClassifiersgd_clf = SGDClassifier(max_iter=1000, tol=1e-3, random_state=42)sgd_clf.fit(X_train, y_train_5) SGDClassifier(alpha=0.0001, average=False, class_weight=None, early_stopping=False, epsilon=0.1, eta0=0.0, fit_intercept=True, l1_ratio=0.15, learning_rate=&#39;optimal&#39;, loss=&#39;hinge&#39;, max_iter=1000, n_iter_no_change=5, n_jobs=None, penalty=&#39;l2&#39;, power_t=0.5, random_state=42, shuffle=True, tol=0.001, validation_fraction=0.1, verbose=0, warm_start=False) 숫자 5 이미지 감지 1sgd_clf.predict([some_digit]) array([ True]) 분류기가 해당하는 이미지가 5를 나타낸다고 추측함.(True) 12from sklearn.model_selection import cross_val_scorecross_val_score(sgd_clf, X_train, y_train_5, cv=3, scoring=&quot;accuracy&quot;) array([0.95035, 0.96035, 0.9604 ]) 성능 측정교차 검증을 사용한 정확도 측정 교차 검증 구현 다음 코드는 사이킷런의 cross_val_score()함수와 거의 같은 작업을 수행하는 코드입니다. 123456789101112131415161718from sklearn.model_selection import StratifiedKFoldfrom sklearn.base import clone# shuffle=False가 기본값이기 때문에 random_state를 삭제하던지 shuffle=True로 지정하라는 경고가 발생합니다.# 0.24버전부터는 에러가 발생하니 shuffle=True을 지정skfolds = StratifiedKFold(n_splits=3, random_state=42, shuffle=True)for train_index, test_index in skfolds.split(X_train, y_train_5): clone_clf = clone(sgd_clf) X_train_folds = X_train[train_index] y_train_folds = y_train_5[train_index] X_test_folds = X_train[train_index] y_test_folds = y_train_5[train_index] clone_clf.fit(X_train_folds, y_train_folds) y_pred = clone_clf.predict(X_test_folds) n_correct = sum(y_pred == y_test_folds) print(n_correct / len(y_pred)) 0.9705 0.91645 0.9715 StractifiedFold 클래스별 비율이 유지되도록 폴드를 만들기 위해 계층적 샘플링 수행 매 반복에서 분류기 객체를 복제하여 훈련 폴드로 훈련시키고 테스트 폴드로 예측을 만듦 올바른 예측의 수를 세어 정확한 예측의 비율 출력 123456from sklearn.base import BaseEstimatorclass Never5Classifier(BaseEstimator): def fit(self, X, y=None): pass def predict(self, X): return np.zeros((len(X), 1), dtype=bool) 12never_5_clf = Never5Classifier()cross_val_score(never_5_clf, X_train, y_train_5, cv=3, scoring=&quot;accuracy&quot;) array([0.91125, 0.90855, 0.90915]) 정확도가 90% 이상으로 나옴 이미지의 10% 정도만 숫자 5이기 때문에 5가 아닌 경우로 예측하면 맞출 확률이 90% 따라서 이 예제는 정확도를 분류기의 성능 측정 지표로 사용하지 않는 이유를 보여줌. 특히 불균형한 데이터셋(어떤 클래스가 다른 것보다 많은 경우)을 다룰 때 더욱 그러함. 알고리즘이 조금씩 변경되어 결과값 변동이 있을 수 있음. 무작위성에 의존함. 연산이 실행되는 순서가 보장되지 않음. 딕셔너리나 셋은 완벽한 재현이 불가능. 오차 행렬 클래스 A의 샘플이 클래스 B로 분류된 횟수를 세는 것 ex) 분류기가 숫자 5의 이미지를 3으로 잘못 분류한 횟수를 알고 싶다면 오차 행렬의 5행 3열을 참고 오차 행렬을 만들려면 실제 타겟과 비교할 수 있도록 먼저 예측값을 만들어야 함테스트 세트로 예측을 만들 수 있지만 테스트 세트는 분류기가 출시 준비를 마치고 나서 프로젝트의 맨 마지막에 사용대신 cross_val_predict()함수 사용 123from sklearn.model_selection import cross_val_predicty_train_pred = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3) cross_val_predict()함수는 k-겹 교차 검증을 수행하지만 평가 점수를 반환하지 않고 각 테스트 폴드에서 얻은 예측을 반환합니다. 모델이 훈련하는 동안 보지 못 했던 데이터에 대해 예측합니다. confusion_matrix()함수를 사용해 오차 행렬 만들기 타깃 글래스(y_train_5)와 예측 클래스(y_train_pred)를 넣고 호출하기. 123from sklearn.metrics import confusion_matrixconfusion_matrix(y_train_5, y_train_pred) array([[53892, 687], [ 1891, 3530]]) 행은 실제 클래스 열은 예측한 클래스 5가 아닌 이미지를 아닌 것으로 정확하게 분류한 것을 진짜 음성이라고 함.5라고 잘 못 분류한 것을 거짓 양성이라고 함.5 이미지를 5가 아닌 것으로 잘 못 분류한 것을 거짓음성이라고 함.정확히 5라고 분류한 것을 진짜 양성이라고 함. 12y_train_perfect_predictions = y_train_5 # 완벽한 분류기일 경우confusion_matrix(y_train_5, y_train_perfect_predictions) array([[54579, 0], [ 0, 5421]]) 분류기의 정밀도 더 요약된 지표가 필요한 경우 양성 예측의 정확도를 활용 확실한 양성 샘플 하나만 예측하면 간단히 완벽한 정밀도를 얻을 수 있지만, 이는 분류기가 다른 모든 양성 샘플을 무시하기 때문에 그리 유용하지 않음.정밀도는 재현율이라는 또 다른 지표와 같이 사용하는 것이 일반적.재현율은 분류기가 정확하게 감지한 양성 샘플의 비율로 민감도 또는 진짜 양성 비율이라고도 함. 정밀도와 재현율사이킷런은 정밀도와 재현율을 포함하여 분류기의 지표를 계산하는 여러 함수 제공 123from sklearn.metrics import precision_score, recall_scoreprecision_score(y_train_5, y_train_pred) 0.8370879772350012 12cm = confusion_matrix(y_train_5, y_train_pred)cm[1, 1] / (cm[0, 1] + cm[1, 1]) 0.8370879772350012 1recall_score(y_train_5, y_train_pred) 0.6511713705958311 1cm[1, 1] / (cm[1, 0] + cm[1, 1]) 0.6511713705958311 F1 점수 = 정밀도와 재현율의 조화 평균 123from sklearn.metrics import f1_scoref1_score(y_train_5, y_train_pred) 0.7325171197343846 1cm[1, 1] / (cm[1, 1] + (cm[1, 0] + cm[0, 1]) / 2) 0.7325171197343847 정밀도/재현율 트레이드오프임곗값을 내리면 재현율이 높아지고 정밀도가 줄어듦 predict() 메소드 대신 dccision_function()메소드를 호출하면 각 샘플의 점수를 얻을 수 있음 이 점수를 기반으로 원하는 임곗값을 정해 예측을 만들 수 있음 12y_scores = sgd_clf.decision_function([some_digit])y_scores array([2164.22030239]) 12threshold = 0y_some_digit_pred = (y_scores &gt; threshold) 1y_some_digit_pred array([ True]) 123threshold = 8000y_some_digit_pred = (y_scores &gt; threshold)y_some_digit_pred array([False]) 이미지가 실제로 숫자 5이고 임곗값이 0일 때는 분류기가 이를 감지했지만, 임곗값을 8천으로 높이면 놓치게 됨 cross_val_predict()함수를 사용해 훈련 세트에 있는 모든 샘플의 점수를 구해야 함.결정 점수를 반환 받도록 지정 12y_scores = cross_val_predict(sgd_clf, X_train, y_train_5, cv=3, method=&quot;decision_function&quot;) precision_recall_curve()함수를 사용하여 가능한 모든 임곗값에 대해 정밀도와 재현율 계산 가능 123from sklearn.metrics import precision_recall_curveprecisions, recalls, thresholds = precision_recall_curve(y_train_5, y_scores) matplotlib을 이용해 임곗값의 함수로 정밀도와 재현율 그리기 12345678910111213141516171819def plot_precision_recall_vs_threshold(precisions, recalls, thresholds): plt.plot(thresholds, precisions[:-1], &quot;b--&quot;, label=&quot;Precision&quot;, linewidth=2) plt.plot(thresholds, recalls[:-1], &quot;g--&quot;, label=&quot;Recall&quot;, linewidth=2) plt.legend(loc=&quot;center right&quot;, fontsize=16) # Not shown in the book plt.xlabel(&quot;Threshold&quot;, fontsize=16) # Not shown plt.grid(True) # Not shown plt.axis([-50000, 50000, 0, 1]) # Not shownrecall_90_precision = recalls[np.argmax(precisions &gt;= 0.90)]threshold_90_precision = thresholds[np.argmax(precisions &gt;= 0.90)]plt.figure(figsize=(8, 4))plot_precision_recall_vs_threshold(precisions, recalls, thresholds)plt.plot([-50000, threshold_90_precision], [0.9, 0.9], &quot;r:&quot;)plt.plot([-50000, threshold_90_precision], [recall_90_precision, recall_90_precision], &quot;r:&quot;)plt.plot([threshold_90_precision], [0.9], &quot;ro&quot;)plt.plot([threshold_90_precision], [recall_90_precision], &quot;ro&quot;)save_fig(&quot;precision_recall_vs_threshold_plot&quot;)plt.show() 그림 저장: precision_recall_vs_threshold_plot 1(y_train_pred == (y_scores &gt; 0)).all() True 1234567891011121314def plot_precision_vs_recall(precisions, recalls): plt.plot(recalls, precisions, &quot;b-&quot;, linewidth=2) plt.xlabel(&quot;Recall&quot;, fontsize=16) plt.ylabel(&quot;Precision&quot;, fontsize=16) plt.axis([0, 1, 0, 1]) plt.grid(True)plt.figure(figsize=(8, 6))plot_precision_vs_recall(precisions, recalls)plt.plot([recall_90_precision, recall_90_precision], [0., 0.9], &quot;r:&quot;)plt.plot([0.0, recall_90_precision], [0.9, 0.9], &quot;r:&quot;)plt.plot([recall_90_precision], [0.9], &quot;ro&quot;)save_fig(&quot;precision_vs_recall_plot&quot;)plt.show() 그림 저장: precision_vs_recall_plot 12threshold_90_precision = thresholds[np.argmax(precisions &gt;= 0.90)]threshold_90_precision 3370.0194991439557 1y_train_pred_90 = (y_scores &gt;= threshold_90_precision) 1precision_score(y_train_5, y_train_pred_90) 0.9000345901072293 1recall_score(y_train_5, y_train_pred_90) 0.4799852425751706 충분히 큰 임곗값을 지정해 정밀도 90%를 달성한 분류기를 만들었으나 재현율이 너무 낮다면 높은 정밀도의 분류기는 의미없음 ROC 곡선거짓 양성 비율(FPR)에 대한 진짜 양성 비율(TPR)의 곡선 ROC곡선을 그리려면 먼저 roc_curve()함수를 사용해 여러 임곗값에서 TPR과 FPR을 계산 해야 함 123from sklearn.metrics import roc_curvefpr, tpr, thresholds = roc_curve(y_train_5, y_scores) 12345678910111213141516def plot_roc_curve(fpr, tpr, label=None): plt.plot(fpr, tpr, linewidth=2, label=label) plt.plot([0,1], [0,1], &#x27;k--&#x27;) # 대각 점선 plt.axis([0,1,0,1]) plt.xlabel(&#x27;False Positive Rate (Fall-Out)&#x27;, fontsize=16) # 축 이름, 그리드 추가 plt.ylabel(&#x27;True Positive Rate (Recall)&#x27;, fontsize=16) plt.grid(True)plt.figure(figsize=(8,6))plot_roc_curve(fpr, tpr)fpr_90 = fpr[np.argmax(tpr &gt;= recall_90_precision)]plt.plot([fpr_90, fpr_90], [0., recall_90_precision], &quot;r:&quot;)plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], &quot;r:&quot;)plt.plot([fpr_90], [recall_90_precision], &quot;ro&quot;)save_fig(&quot;roc_curve_plot&quot;)plt.show() 그림 저장: roc_curve_plot 붉은 점이 선택한 비율의 지점(43.68% 재현율) 재현율이 높을수록 분류기가 만드는 거짓 양성이 늘어남. 점선은 완전한 랜덤 분류기의 ROC 곡선을 뜻함. 좋은 분류기는 이 점선에서 최대한 멀리 떨어져 있어야 함. 양성 클래스가 드물거나 거짓 음성보다 거짓 양성이 더 중요할 때 PR 곡선 사용 그렇지 않으면 ROC 곡선을 사용 123from sklearn.metrics import roc_auc_scoreroc_auc_score(y_train_5, y_scores) 0.9604938554008616 predict_proba()메소드는 샘플이 행, 클래스가 열이고 샘플이 주어진 클래스에 속할 확률을 담은 배열을 반환 1234from sklearn.ensemble import RandomForestClassifierforest_clf = RandomForestClassifier(n_estimators=100, random_state=42)y_probas_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3, method=&quot;predict_proba&quot;) roc_curve()함수는 레이블과 점수를 기대함. 점수 대신에 클래스 확률을 전달할 수 있음. 12y_scores_forest = y_probas_forest[:, 1] # 점수 = 양성 클래스의 확률fpr_forest, tpr_forest, theresholds_forest = roc_curve(y_train_5, y_scores_forest) 1234567891011121314recall_for_forest = tpr_forest[np.argmax(fpr_forest &gt;= fpr_90)]plt.figure(figsize=(8,6))plt.plot(fpr, tpr, &quot;b:&quot;, linewidth=2, label=&quot;SGD&quot;)plot_roc_curve(fpr_forest, tpr_forest, &quot;Random Forest&quot;)plt.plot([fpr_90, fpr_90], [0., recall_90_precision], &quot;r:&quot;)plt.plot([0.0, fpr_90], [recall_90_precision, recall_90_precision], &quot;r:&quot;)plt.plot([fpr_90], [recall_90_precision], &quot;ro&quot;)plt.plot([fpr_90, fpr_90], [0., recall_for_forest], &quot;r:&quot;)plt.plot([fpr_90], [recall_for_forest], &quot;ro&quot;)plt.grid(True)plt.legend(loc=&quot;lower right&quot;, fontsize=16)save_fig(&quot;roc_curve_comparison_plot&quot;)plt.show() 그림 저장: roc_curve_comparison_plot ROC 곡선 비교 : 랜덤 포레스트 분류기가 SGD 분류기보다 훨씬 좋습니다. 랜덤 포레스트의 ROC 곡선이 왼쪽 위 모서리에 더 가까워 AUC값이 크기 때문 1roc_auc_score(y_train_5, y_scores_forest) 0.9983436731328145 12y_train_pred_forest = cross_val_predict(forest_clf, X_train, y_train_5, cv=3)precision_score(y_train_5, y_train_pred_forest) 0.9905083315756169 1recall_score(y_train_5, y_train_pred_forest) 0.8662608374838591 99.0% 정밀도와 86.6% 재현율 다중 분류 Ova, Ovr 전략 : 이미지를 분류할 때 각 분류의 결정 점수 중에서 가장 높은 것을 클래스로 선택 OvO 전략 : 1,2 1,3과 같이 각각의 숫자의 조합마다 이진 분류기를 훈련 다중 클래스 분류 작업에 이진 분류 알고리즘을 선택하면 사이킷런이 알고리즘에 따라 자동으로 OvR 또는 OvO를 실행합니다. sklearn.svm.SVC 클래스를 사용해서 서포트 벡터 머신 분류기 테스트 12345from sklearn.svm import SVCsvm_clf = SVC(gamma=&quot;auto&quot;, random_state=42)svm_clf.fit(X_train[:1000], y_train[:1000])svm_clf.predict([some_digit]) array([5], dtype=uint8) 5를 구별한 타깃 클래스(y_train_5) 대신 0~9까지의 원래 타깃 클래스(y_train)을 사용해 SVC 훈련. 그 다음 예측 하나를 만들고 내부에서는 사이킷런이 OvO 전략을 사용해 45개의 이진 분류기를 훈련시키고 각각의 결정 점수를 얻어 점수가 가장 높은 클래스를 선택 decision_function()메소드를 호출하면 샘플당 10개의 점수를 반환함. 이 점수는 클래스마다 하나씩임 12some_digit_scores = svm_clf.decision_function([some_digit])some_digit_scores array([[ 2.81585438, 7.09167958, 3.82972099, 0.79365551, 5.8885703 , 9.29718395, 1.79862509, 8.10392157, -0.228207 , 4.83753243]]) 가장 높은 점수가 클래스 5에 해당하는 값 1np.argmax(some_digit_scores) 5 1svm_clf.classes_ array([0, 1, 2, 3, 4, 5, 6, 7, 8, 9], dtype=uint8) 분류기가 훈련될 때 classes_ 속성에 타깃 클래스의 리스트를 값으로 정렬하여 저장. 위 예제에서는 classes_ 배열에 있는 각 클래스의 인덱스가 클래스 값 자체와 같음(인덱스 5에 해당하는 클래스의 값은 5) 그러나 이런경우는 드뭄 사이킷런에서 OvO나 OvR을 사용하도록 강제하려면 OneVsOneClassifier나 OneVsRestClassifier를 사용. 이진 분류기 인스턴스를 만들어 객체를 생성할 때 전달하면 됨. 다음 코드는 SVC기반으로 OvR 전략을 사용하는 다중 분류기를 만듦 1234from sklearn.multiclass import OneVsRestClassifierovr_clf = OneVsRestClassifier(SVC(gamma=&quot;auto&quot;, random_state=42))ovr_clf.fit(X_train[:1000], y_train[:1000])ovr_clf.predict([some_digit]) array([5], dtype=uint8) SGDClassifier(or RandomForestClassifier)를 훈련시키는 것도 간단함 1len(ovr_clf.estimators_) 10 12sgd_clf.fit(X_train, y_train)sgd_clf.predict([some_digit]) array([3], dtype=uint8) 이 경우 SGD분류기는 직접 샘플을 다중 클래스로 분류할 수 있기 때문에 별도로 사이킷런의 OvR이나 OvO를 적용할 필요가 없음. decision_function()메소드는 클래스마다 하나의 값을 반환함. 1sgd_clf.decision_function([some_digit]) array([[-31893.03095419, -34419.69069632, -9530.63950739, 1823.73154031, -22320.14822878, -1385.80478895, -26188.91070951, -16147.51323997, -4604.35491274, -12050.767298 ]]) 분류 평가에는 일반적으로 교차 검증을 사용. cross_val_score() 함수를 사용해 SGDClassifier의 정확도를 평가 1cross_val_score(sgd_clf, X_train, y_train, cv=3, scoring=&quot;accuracy&quot;) array([0.87365, 0.85835, 0.8689 ]) 모든 테스트 폴드에서 84% 이상을 얻었음. 랜덤 분류기 사용시 10% 정확도를 얻었을 것이므로 성능을 더 높일 여지가 있음. 입력의 스케일을 조정 1234from sklearn.preprocessing import StandardScalerscaler = StandardScaler()X_train_scaled = scaler.fit_transform(X_train.astype(np.float64))cross_val_score(sgd_clf, X_train_scaled, y_train, cv=3, scoring=&quot;accuracy&quot;) array([0.8983, 0.891 , 0.9018]) 에러 분석오차 행렬 살펴보기. cross_val_predict() 함수를 사용해 예측을 만들고 confusion_matrix()함수 호출 123y_train_pred = cross_val_predict(sgd_clf, X_train_scaled, y_train, cv=3)conf_mx = confusion_matrix(y_train, y_train_pred)conf_mx array([[5577, 0, 22, 5, 8, 43, 36, 6, 225, 1], [ 0, 6400, 37, 24, 4, 44, 4, 7, 212, 10], [ 27, 27, 5220, 92, 73, 27, 67, 36, 378, 11], [ 22, 17, 117, 5227, 2, 203, 27, 40, 403, 73], [ 12, 14, 41, 9, 5182, 12, 34, 27, 347, 164], [ 27, 15, 30, 168, 53, 4444, 75, 14, 535, 60], [ 30, 15, 42, 3, 44, 97, 5552, 3, 131, 1], [ 21, 10, 51, 30, 49, 12, 3, 5684, 195, 210], [ 17, 63, 48, 86, 3, 126, 25, 10, 5429, 44], [ 25, 18, 30, 64, 118, 36, 1, 179, 371, 5107]]) matplotlib의 matshow()함수를 사용해 이미지로 표현하면 보기 편리할 수 있음 사이킷런 0.22버전부터는 sklearn.metrics.plot_confusion_matrix()함수를 사용할 수 있습니다. 123456def plot_confusion_matrix(matrix): fig = plt.figure(figsize=(8,8)) ax = fig.add_subplot(111) cax = ax.matshow(matrix) fig.colorbar(cax) 123plt.matshow(conf_mx, cmap=plt.cm.gray)save_fig(&quot;confusion_matrix_plot&quot;, tight_layout=False)plt.show() 그림 저장: confusion_matrix_plot 데이터셋에 숫자5의 이미지가 적거나 분류기가 숫자 5를 다른 숫자만큼 잘 분류하지 못 함.두 경우의 대하여 확인 그래프의 에러 부분에 초점을 맞춰 오차 행렬의 각 값을 대응되는 클래스의 이미지 개수로 나누어 에러 비율 비교 12row_sums = conf_mx.sum(axis=1, keepdims=True)norm_conf_mx = conf_mx / row_sums 다른 항목은 유지하고 주 대각선만 0으로 채워서 그래프 그리기 1234np.fill_diagonal(norm_conf_mx, 0)plt.matshow(norm_conf_mx, cmap=plt.cm.gray)save_fig(&quot;confusion_matrix_errors_plot&quot;, tight_layout=False)plt.show() 그림 저장: confusion_matrix_errors_plot 행은 실제 클래스를 나타내고 열은 예측한 클래스를 나타냄. 클래스 8의 열이 상당히 밝으므로 많은 이미지가 8로 잘못 분류 되었음을 암시 하지만 클래스 8의 행은 그리 나쁘지 않은 걸로 보아 실제 8이 적절하게 8로 분류되었음 3과 5가 서로 많이 혼동되고 있음 12345678910111213cl_a, cl_b = 3, 5X_aa = X_train[(y_train == cl_a) &amp; (y_train_pred == cl_a)]X_ab = X_train[(y_train == cl_a) &amp; (y_train_pred == cl_b)]X_ba = X_train[(y_train == cl_b) &amp; (y_train_pred == cl_a)]X_bb = X_train[(y_train == cl_b) &amp; (y_train_pred == cl_b)]plt.figure(figsize=(8,8))plt.subplot(221); plot_digits(X_aa[:25], images_per_row=5)plt.subplot(222); plot_digits(X_ab[:25], images_per_row=5)plt.subplot(223); plot_digits(X_ba[:25], images_per_row=5)plt.subplot(224); plot_digits(X_bb[:25], images_per_row=5)save_fig(&quot;error_analysis_digits_plot&quot;)plt.show() 그림 저장: error_analysis_digits_plot 원인은 선형 모델인 SGDClassifier를 사용했기 때문이며 선형 분류기는 클래스마다 픽셀에 가중치를 할당하고 새로운 이미지에 대해 단순히 픽셀 강도의 가중치 합을 클래스의 점수로 계산함. 따라서 3과 5는 몇개의 픽셀만 다르기 때문에 모델이 쉽게 혼동함. 분류기는 이미지의 위치나 회전 방향에 매우 민감함.이 경우에 대해서 에러를 줄이는 방법 중에 하나는 이미지를 중앙에 위치시키고 회전되어 있지 않도록 전처리 하는 것 다중 레이블 분류여러 개의 이진 꼬리표를 출력하는 분류 시스템 12345678from sklearn.neighbors import KNeighborsClassifiery_train_large = (y_train &gt;= 7)y_train_odd = (y_train % 2 == 1)y_multilabel = np.c_[y_train_large, y_train_odd]knn_clf = KNeighborsClassifier()knn_clf.fit(X_train, y_multilabel) KNeighborsClassifier(algorithm=&#39;auto&#39;, leaf_size=30, metric=&#39;minkowski&#39;, metric_params=None, n_jobs=None, n_neighbors=5, p=2, weights=&#39;uniform&#39;) 각 숫자 이미지에 두 개의 타깃 레이블이 담긴 y_multilabel 배열을 만듦. 첫 번째는 숫자가 큰 값(7,8,9)인지 나타내고 두 번째는 홀수인지 나타냄. KNeighborsClassifier 인스턴스를 만들고 다중 타깃 배열을 사용하여 훈련. 이제 예측을 만들면 레이블이 두 개 출력 1knn_clf.predict([some_digit]) array([[False, True]]) 숫자 5는 크지 않고 홀수. 모든 레이블에 대한 F1점수의 평균 계산 12y_train_knn_pred = cross_val_predict(knn_clf, X_train, y_multilabel, cv=3)f1_score(y_multilabel, y_train_knn_pred, average=&quot;macro&quot;) 0.976410265560605 레이블에 클래스의 지지도를 가중치로 주는 것. 이전 코드에서 average=”weighted”로 설정 다중 출력 분류다중 레이블 분류에서 한 레이블이 다중 클래스가 될 수 있도록 일반화 한 것(값을 두 개 이상 가질 수 있음) 분류기의 출력이 다중 레이블(픽셀당 한 레이블)이고 각 레이블은 값을 여러개 가짐(0~255) 분류와 회귀 사이의 경계는 때때로 모호함 픽셀 강도 예측은 분류보다 회귀와 비슷함 다중 출력 시스템이 분류 작업에 국한되지도 않음 그래서 샘플마다 클래스와 값을 모두 포함하는 다중 레이블이 출력되는 시스템도 가능 MNIST 이미지에서 추출한 훈련 세트와 테스트 세트에 numpy의 randint() 함수를 사용하여 픽셀 강도에 잡음을 추가함 123456noise = np.random.randint(0, 100, (len(X_train), 784))X_train_mod = X_train + noisenoise = np.random.randint(0, 100, (len(X_test), 784))X_test_mod = X_test + noisey_train_mod = X_trainy_test_mod = X_test 12345some_index = 0plt.subplot(121); plot_digit(X_test_mod[some_index])plt.subplot(122); plot_digit(X_test_mod[some_index])save_fig(&quot;noisy_digit_example_plot&quot;)plt.show() 그림 저장: noisy_digit_example_plot 테스트 세트에서 이미지를 하나 선택하고(테스트 데이터를 들여다 보는 것이 아님) 분류기를 훈련시켜 이 이미지를 깨끗하게 처리함 1234knn_clf.fit(X_train_mod, y_train_mod)clean_digit = knn_clf.predict([X_test_mod[some_index]])plot_digit(clean_digit)save_fig(&quot;cleaned_digit_example_plot&quot;) 그림 저장: cleaned_digit_example_plot 분류 작업에서 좋은 측정 지표를 선택, 적절한 정밀도/재현율 트레이드오프를 고르고, 분류기를 비교해야 함.","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"Feature Engineering","slug":"Feature-Engineering","date":"2021-04-08T12:48:11.000Z","updated":"2021-04-09T13:32:38.755Z","comments":true,"path":"2021/04/08/Feature-Engineering/","link":"","permalink":"https://kjm94.github.io/2021/04/08/Feature-Engineering/","excerpt":"","text":"데이터 수집 시각화 -&gt; 변수 간의 조합 기초통계 : Feature Engineering Feature Engineering 이상치 처리, 중복값 제거, 문자 데이터 –&gt; 수치 (인코딩) 정규화, 표준화, 도출 변수 및 불필요한 삭제 PCA(차원 축소),EFA 결측치 확인 : 1) 결측치 제거 : 2) 결측치 채우기 - 중간값, 빈도수 값 많은 것 넣기 - Imputation : 3) 결측치 도메인 활용 왜도처리(Skewnewss) 도출 변수 Label Encoding –&gt; 종속변수에만 사용 Ordinal Encoding –&gt; 독립변수에만 사용 -&gt; 문자를 숫자로 바꿈 -&gt; Default, 가~하, A-Z 순으로 숫자 바뀜 -&gt; 순서형 One - Hot Encoding –&gt; 독립변수에만 사용 -&gt; 명목형 훈련 데이터 / 테스트 데이터 모형 학습 (다양한 모형 공부 필요) 예측 결과 예측 결과 평가 최종 모델 선정 및 최종 예측 결과 캐글 대회 제출 –&gt; 주 목적, 예측 정확성 향상상) 최종 모델 선정 및 최종 예측 결과9) 캐글 대회 제출–&gt; 주 목적, 예측 정확성 향상","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"Pandas10min","slug":"Pandas10min","date":"2021-04-07T14:07:07.000Z","updated":"2021-04-07T14:14:14.135Z","comments":true,"path":"2021/04/07/Pandas10min/","link":"","permalink":"https://kjm94.github.io/2021/04/07/Pandas10min/","excerpt":"","text":"Pandas new usersimport12import numpy as npimport pandas as pd 객체 생성123s = pd.Series([1,3,5,np.nan,6,8])s 0 1.0 1 3.0 2 5.0 3 NaN 4 6.0 5 8.0 dtype: float64 DataFrameDatetime 인덱스와 레이블이 지정된 열이 있는 Numpy 배열을 전달하여 생성 123dates = pd.date_range(&quot;20130101&quot;, periods=6)dates DatetimeIndex([&#39;2013-01-01&#39;, &#39;2013-01-02&#39;, &#39;2013-01-03&#39;, &#39;2013-01-04&#39;, &#39;2013-01-05&#39;, &#39;2013-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;) 123df = pd.DataFrame(np.random.randn(6,4),index=dates, columns=list(&quot;ABCD&quot;))df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D 2013-01-01 -1.338161 0.110530 0.536230 2.030842 2013-01-02 0.357603 -0.355747 0.054411 -0.102109 2013-01-03 -0.319073 -1.183950 0.094337 0.616546 2013-01-04 0.350805 1.549371 1.245585 -0.153351 2013-01-05 -0.515572 -2.377644 -0.042456 0.071252 2013-01-06 -0.260635 -1.106064 -1.276920 1.408237 DataFrame 시리즈와 같은 변환을 할 수 있는 개체의 DICT를 전달하여 만들기. 123456789101112df2 = pd.DataFrame( &#123; &quot;A&quot; : 1.0, &quot;B&quot; : pd.Timestamp(&quot;20130102&quot;), &quot;C&quot; : pd.Series(1, index=list(range(4)), dtype=&quot;float32&quot;), &quot;D&quot; : np.array([3] * 4, dtype=&quot;int32&quot;), &quot;E&quot; : pd.Categorical([&quot;test&quot;,&quot;train&quot;,&quot;test&quot;,&quot;train&quot;]), &quot;F&quot; : &quot;foo&quot; &#125;)df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D E F 0 1.0 2013-01-02 1.0 3 test foo 1 1.0 2013-01-02 1.0 3 train foo 2 1.0 2013-01-02 1.0 3 test foo 3 1.0 2013-01-02 1.0 3 train foo 그 결과 열 DataFrame은 다른 dtypes를 갖습니다. 1df2.dtypes A float64 B float64 dtype: object 데이터 보기프레임의 상단 및 하단 행을 보는 방법 1df.head() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D 2013-01-01 -1.338161 0.110530 0.536230 2.030842 2013-01-02 0.357603 -0.355747 0.054411 -0.102109 2013-01-03 -0.319073 -1.183950 0.094337 0.616546 2013-01-04 0.350805 1.549371 1.245585 -0.153351 2013-01-05 -0.515572 -2.377644 -0.042456 0.071252 1df.tail(3) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D 2013-01-04 0.350805 1.549371 1.245585 -0.153351 2013-01-05 -0.515572 -2.377644 -0.042456 0.071252 2013-01-06 -0.260635 -1.106064 -1.276920 1.408237 색인, 열 표시 1df.index DatetimeIndex([&#39;2013-01-01&#39;, &#39;2013-01-02&#39;, &#39;2013-01-03&#39;, &#39;2013-01-04&#39;, &#39;2013-01-05&#39;, &#39;2013-01-06&#39;], dtype=&#39;datetime64[ns]&#39;, freq=&#39;D&#39;) 1df.columns Index([&#39;A&#39;, &#39;B&#39;, &#39;C&#39;, &#39;D&#39;], dtype=&#39;object&#39;) DataFrame.to_numpy()기본 데이터의 Numpy 표현을 제공합니다. DataFrame pandas와 Numpy의 근본적인 차이로 인해 데이터 유형이 다른 열이 있는 경우 이 작업은 비용이 많이들 수 있습니다.Numpy 배열에는 전체 배열에 대해 하나의 dtype이 있는 반면 pandas DataFrames에는 열당 하나의 dtype이 있습니다. DataFrame.to_numpy()를 호출하면 pandas는 DataFrame의 모든 dtype을 보유할 수 있는 Numpy dtype을 찾습니다. 결국 object 모든 값을 python 객체로 캐스팅해야 하는식으로 끝날 수 있습니다. df에 대한, DataFrame 모든 부동 소수점 값, DataFrame.to_numpy() 빠르고 및 복사 데이터를 필요로 하지 않는다. 1df.to_numpy() array([[-1.33816087, 0.11053004, 0.53623007, 2.03084207], [ 0.35760296, -0.35574745, 0.0544108 , -0.10210902], [-0.31907276, -1.18395015, 0.09433678, 0.61654553], [ 0.35080472, 1.54937131, 1.24558483, -0.15335078], [-0.51557247, -2.37764397, -0.04245553, 0.07125205], [-0.26063518, -1.10606377, -1.27691993, 1.40823689]]) df2는 DataFrame 여러 dtype으로, DataFrame.to_numpy() 상대적으로 비싸다. 1df2.to_numpy() array([[-0.37591379, 0.80689645], [ 2.71741139, -1.18659735], [ 0.34445035, 0.15736656], [ 0.21151164, 0.70306021]]) DataFrame.to_numpy()출력에 색인 또는 열 레이블을 포함 하지 않습니다. describe() 데이터에 대한 빠른 통계 요약을 보여줍니다. 1df.describe() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D count 6.000000 6.000000 6.000000 6.000000 mean -0.287506 -0.560584 0.101865 0.645236 std 0.629478 1.336571 0.827158 0.897621 min -1.338161 -2.377644 -1.276920 -0.153351 25% -0.466448 -1.164479 -0.018239 -0.058769 50% -0.289854 -0.730906 0.074374 0.343899 75% 0.197945 -0.006039 0.425757 1.210314 max 0.357603 1.549371 1.245585 2.030842 데이터 전치 : 1df.T .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; 2013-01-01 2013-01-02 2013-01-03 2013-01-04 2013-01-05 2013-01-06 A -1.338161 0.357603 -0.319073 0.350805 -0.515572 -0.260635 B 0.110530 -0.355747 -1.183950 1.549371 -2.377644 -1.106064 C 0.536230 0.054411 0.094337 1.245585 -0.042456 -1.276920 D 2.030842 -0.102109 0.616546 -0.153351 0.071252 1.408237 축으로 정렬 : 1df.sort_index(axis=1, ascending=False) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; D C B A 2013-01-01 2.030842 0.536230 0.110530 -1.338161 2013-01-02 -0.102109 0.054411 -0.355747 0.357603 2013-01-03 0.616546 0.094337 -1.183950 -0.319073 2013-01-04 -0.153351 1.245585 1.549371 0.350805 2013-01-05 0.071252 -0.042456 -2.377644 -0.515572 2013-01-06 1.408237 -1.276920 -1.106064 -0.260635 값으로 정렬 : 1df.sort_values(by=&quot;B&quot;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D 2013-01-05 -0.515572 -2.377644 -0.042456 0.071252 2013-01-03 -0.319073 -1.183950 0.094337 0.616546 2013-01-06 -0.260635 -1.106064 -1.276920 1.408237 2013-01-02 0.357603 -0.355747 0.054411 -0.102109 2013-01-01 -1.338161 0.110530 0.536230 2.030842 2013-01-04 0.350805 1.549371 1.245585 -0.153351 선택 선택 및 설정을 위한 표준 python / Numpy 표현식은 직관적이고 대화형 작업에 유용하지만 프로덕션 코드의 경우 최적화 된 pandas 데이터 액세스 방법 .at인 .iat, .loc및 .lioc. 얻기단일 열을 선택하면 다음 Series와 같은 결과가 생성됩니다. 1df[&quot;A&quot;] 2013-01-01 -1.338161 2013-01-02 0.357603 2013-01-03 -0.319073 2013-01-04 0.350805 2013-01-05 -0.515572 2013-01-06 -0.260635 Freq: D, Name: A, dtype: float64 []행을 분할하는 via를 선택합니다. 1df[0:3] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D 2013-01-01 -1.338161 0.110530 0.536230 2.030842 2013-01-02 0.357603 -0.355747 0.054411 -0.102109 2013-01-03 -0.319073 -1.183950 0.094337 0.616546 1df[&quot;20130102&quot;:&quot;20130104&quot;] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D 2013-01-02 0.357603 -0.355747 0.054411 -0.102109 2013-01-03 -0.319073 -1.183950 0.094337 0.616546 2013-01-04 0.350805 1.549371 1.245585 -0.153351 라벨로 선택레이블을 사용하여 횡단면을 얻으려면 : 1df.loc[dates[0]] A -1.338161 B 0.110530 C 0.536230 D 2.030842 Name: 2013-01-01 00:00:00, dtype: float64 라벨로 다축 선택 : 1df.loc[:,[&quot;A&quot;,&quot;B&quot;]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B 2013-01-01 -1.338161 0.110530 2013-01-02 0.357603 -0.355747 2013-01-03 -0.319073 -1.183950 2013-01-04 0.350805 1.549371 2013-01-05 -0.515572 -2.377644 2013-01-06 -0.260635 -1.106064 레이블 슬라이싱을 표시하며 두 엔드 포인트가 모두 포함됩니다. 1df.loc[&quot;20130102&quot;:&quot;20130104&quot;,[&quot;A&quot;,&quot;B&quot;]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B 2013-01-02 0.357603 -0.355747 2013-01-03 -0.319073 -1.183950 2013-01-04 0.350805 1.549371 반환 된 객체의 크기 감소 : 1df.loc[&quot;20130102&quot;,[&quot;A&quot;,&quot;B&quot;]] A 0.357603 B -0.355747 Name: 2013-01-02 00:00:00, dtype: float64 스칼라 값을 얻으려면 : 1df.loc[dates[0], &quot;A&quot;] -1.3381608728638592 스칼라에 빠르게 액세스하려면 : 1df.at[dates[0], &quot;A&quot;] -1.3381608728638592 위치 별 선택전달 된 정수의 위치를 통해 선택 : 1df.iloc[3] A 0.350805 B 1.549371 C 1.245585 D -0.153351 Name: 2013-01-04 00:00:00, dtype: float64 정수 조각으로 numpy / python과 유사하게 작동합니다. 1df.iloc[3:5, 0:2] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B 2013-01-04 0.350805 1.549371 2013-01-05 -0.515572 -2.377644 Numpy / python 스타일과 유사한 정수 위치 목록 : 1df.iloc[[1,2,4],[0,2]] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A C 2013-01-02 0.357603 0.054411 2013-01-03 -0.319073 0.094337 2013-01-05 -0.515572 -0.042456 행을 명시적으로 분할하려면 : 1df.iloc[1:3,:] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D 2013-01-02 0.357603 -0.355747 0.054411 -0.102109 2013-01-03 -0.319073 -1.183950 0.094337 0.616546 열을 명시적으로 분할하려면 다음을 수행하십시오. 1df.iloc[:,1:3] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; B C 2013-01-01 0.110530 0.536230 2013-01-02 -0.355747 0.054411 2013-01-03 -1.183950 0.094337 2013-01-04 1.549371 1.245585 2013-01-05 -2.377644 -0.042456 2013-01-06 -1.106064 -1.276920 명시적으로 값을 얻으려면 : 1df.iloc[1,1] -0.3557474474984722 스칼라에 빠르게 액세스하려면 : 1df.iat[1,1] -0.3557474474984722 불 인덱싱단일 열의 값을 사용하여 데이터를 선택합니다. 1df[df[&quot;A&quot;]&gt;0] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D 2013-01-02 0.357603 -0.355747 0.054411 -0.102109 2013-01-04 0.350805 1.549371 1.245585 -0.153351 불 조건이 충족되는 DataFrame에서 값 선택 1df[df &gt; 0] .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D 2013-01-01 NaN 0.110530 0.536230 2.030842 2013-01-02 0.357603 NaN 0.054411 NaN 2013-01-03 NaN NaN 0.094337 0.616546 2013-01-04 0.350805 1.549371 1.245585 NaN 2013-01-05 NaN NaN NaN 0.071252 2013-01-06 NaN NaN NaN 1.408237 isin()필터링 방법 사용 : 12345df2 = df.copy()df2[&quot;E&quot;] = [&quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;four&quot;, &quot;three&quot;]df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D E 2013-01-01 -1.338161 0.110530 0.536230 2.030842 one 2013-01-02 0.357603 -0.355747 0.054411 -0.102109 one 2013-01-03 -0.319073 -1.183950 0.094337 0.616546 two 2013-01-04 0.350805 1.549371 1.245585 -0.153351 three 2013-01-05 -0.515572 -2.377644 -0.042456 0.071252 four 2013-01-06 -0.260635 -1.106064 -1.276920 1.408237 three 설정새 열을 설정하면 인덱스별로 데이터가 자동으로 정렬됩니다. 12345s1 = pd.Series([1,2,3,4,5,6], index=pd.date_range(&quot;20130102&quot;, periods=6))s1df[&quot;F&quot;] = s1 라벨 별 설정 값: 1df.at[dates[0], &quot;A&quot;] = 0 위치 별 설정 값 : 1df.iat[0,1]=0 Numpy 배열로 할당하여 설정: 1df.loc[:, &quot;D&quot;] = np.array([5] * len(df)) 이전 설정 작업의 결과 : 1df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D F 2013-01-01 0.000000 0.000000 0.536230 5 NaN 2013-01-02 0.357603 -0.355747 0.054411 5 1.0 2013-01-03 -0.319073 -1.183950 0.094337 5 2.0 2013-01-04 0.350805 1.549371 1.245585 5 3.0 2013-01-05 -0.515572 -2.377644 -0.042456 5 4.0 2013-01-06 -0.260635 -1.106064 -1.276920 5 5.0 where 설정이 있는 작업 12345df2 = df.copy()df2[df2 &gt; 0] = -df2df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D F 2013-01-01 0.000000 0.000000 -0.536230 -5 NaN 2013-01-02 -0.357603 -0.355747 -0.054411 -5 -1.0 2013-01-03 -0.319073 -1.183950 -0.094337 -5 -2.0 2013-01-04 -0.350805 -1.549371 -1.245585 -5 -3.0 2013-01-05 -0.515572 -2.377644 -0.042456 -5 -4.0 2013-01-06 -0.260635 -1.106064 -1.276920 -5 -5.0 누락 된 데이터pandas는 주로 값 np.nan을 사용하여 누락 된 데이터를 나타냅니다. 기본적으로 계산에 포함되지 않습니다. 재 인덱싱을 사용하면 지정된 축에서 인덱스를 변경/ 추가/ 삭제할 수 있습니다. 이것은 데이터의 복사본을 반환합니다. 12345df1 = df.reindex(index=dates[0:4], columns=list(df.columns) + [&quot;E&quot;])df1.loc[dates[0] : dates[1], &quot;E&quot;] = 1df1 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D F E 2013-01-01 0.000000 0.000000 0.536230 5 NaN 1.0 2013-01-02 0.357603 -0.355747 0.054411 5 1.0 1.0 2013-01-03 -0.319073 -1.183950 0.094337 5 2.0 NaN 2013-01-04 0.350805 1.549371 1.245585 5 3.0 NaN 누락 된 데이터가 있는 행을 삭제합니다. 1df1.dropna(how=&quot;any&quot;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D F E 2013-01-02 0.357603 -0.355747 0.054411 5 1.0 1.0 누락 된 데이터 채우기. 1df1.fillna(value=5) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D F E 2013-01-01 0.000000 0.000000 0.536230 5 5.0 1.0 2013-01-02 0.357603 -0.355747 0.054411 5 1.0 1.0 2013-01-03 -0.319073 -1.183950 0.094337 5 2.0 5.0 2013-01-04 0.350805 1.549371 1.245585 5 3.0 5.0 값이 불 인 마스크를 가져옵니다. nan 1pd.isna(df1) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D F E 2013-01-01 False False False False True False 2013-01-02 False False False False False False 2013-01-03 False False False False False True 2013-01-04 False False False False False True 통계일반적으로 연산은 누락 된 데이터를 제외합니다. 기술 통계 수행 : 1df.mean() A -0.064479 B -0.579006 C 0.101865 D 5.000000 F 3.000000 dtype: float64 다른 축에서 동일한 작업 : 1df.mean(1) 2013-01-01 1.384058 2013-01-02 1.211253 2013-01-03 1.118263 2013-01-04 2.229152 2013-01-05 1.212866 2013-01-06 1.471276 Freq: D, dtype: float64 차원이 다르고 정렬이 필요한 개체로 작동합니다. 또한 Pandas는 지정된 차원을 따라 자동으로 발송됩니다. 12345s = pd.Series([1,3,5,np.nan,6,8], index=dates).shift(2)sdf.sub(s, axis=&quot;index&quot;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D F 2013-01-01 NaN NaN NaN NaN NaN 2013-01-02 NaN NaN NaN NaN NaN 2013-01-03 -1.319073 -2.183950 -0.905663 4.0 1.0 2013-01-04 -2.649195 -1.450629 -1.754415 2.0 0.0 2013-01-05 -5.515572 -7.377644 -5.042456 0.0 -1.0 2013-01-06 NaN NaN NaN NaN NaN 데이터에 함수 적용 : 123df.apply(np.cumsum)df.apply(lambda x: x.max() - x.min()) A 0.873175 B 3.927015 C 2.522505 D 0.000000 F 4.000000 dtype: float64 히스토그램12345s = pd.Series(np.random.randint(0,7,size=10))ss.value_counts() 6 3 0 3 5 2 3 1 1 1 dtype: int64 문자열 메소드시리즈에는 str 아래 코드 스 니펫에서와 같이 배열의 각 요소에서 쉽게 조작할 수 있도록 속성에 문자열 처리 메소드 세트가 있습니다. 패턴일치는 str일반적으로 기본적으로 정규식을 사용하며 경우에 따라 항상 정규식을 사용합니다. 123s = pd.Series([&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;Aaba&quot;,&quot;Baca&quot;, np.nan, &quot;CABA&quot;, &quot;dog&quot;, &quot;cat&quot;])s.str.lower() 0 a 1 b 2 c 3 aaba 4 baca 5 NaN 6 caba 7 dog 8 cat dtype: object 병합ConcatPandas는 Series 및 DataFrame 객체를 결합 / 병합 유형 작업의 경우 인덱스 및 관계형 대수 기능에 대한 다양한 종류의 세트 로직과 함께 쉽게 결합 할 수 있는 다양한 기능을 제공합니다. pandas 객체를 다음과 함께 연결 concat(): 123456789df = pd.DataFrame(np.random.randn(10, 4))df# break it into piecespieces = [df[:3],df[3:7],df[7:]]pd.concat(pieces) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; 0 1 2 3 0 -1.192838 0.384087 0.887058 -1.348107 1 1.335282 -0.076665 0.227045 -0.612258 2 -0.483729 1.188195 -0.448694 -2.713682 3 -0.579994 -0.640704 -1.267504 -0.006364 4 1.413399 1.118911 -0.301100 0.044948 5 0.785531 -1.443541 -1.211024 -0.372210 6 0.006017 -1.521360 0.165257 0.633229 7 -0.633135 0.657720 0.524750 -1.968084 8 0.400773 -1.014635 2.229316 -1.433340 9 0.820736 -0.556207 -0.448710 1.945929 a에 열을 추가하는 DataFrame것은 비교적 빠릅니다. 그러나 행을 추가하려면 복사본이 필요하며 비용이 많이들 수 있습니다. 반복적으로 레코드를 추가하여 DataFrame을 빌드하는 대신 미리 빌드 된 레코드 목록을 생성자에 전달하는 것이 좋습니다. 가입SQL스타일이 병합됩니다. 12345678left = pd.DataFrame(&#123;&quot;key&quot;:[&quot;foo&quot;,&quot;foo&quot;],&quot;lval&quot;:[1,2]&#125;)right = pd.DataFrame(&#123;&quot;key&quot;:[&quot;foo&quot;,&quot;foo&quot;],&quot;rval&quot;:[4,5]&#125;)leftrightpd.merge(left, right, on=&quot;key&quot;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; key lval rval 0 foo 1 4 1 foo 1 5 2 foo 2 4 3 foo 2 5 주어질 수 있는 또 다른 예는 다음과 같습니다. 12345678left = pd.DataFrame(&#123;&quot;key&quot; : [&quot;foo&quot;,&quot;bar&quot;], &quot;lval&quot; : [1,2]&#125;)right = pd.DataFrame(&#123;&quot;key&quot; : [&quot;foo&quot;,&quot;bar&quot;], &quot;lval&quot; : [4,5]&#125;)leftrightpd.merge(left, right, on=&quot;key&quot;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; key lval_x lval_y 0 foo 1 4 1 bar 2 5 그룹화“그룹 별”은 다음 단계 중 하나 이상을 포함하는 프로세스를 의미합니다. 일부 기준에 따라 데이터를 그룹으로 분할 각 그룹에 독립적으로 기능 적용 결과를 데이터 구조로 결합 12345678df = pd.DataFrame(&#123; &quot;A&quot; : [&quot;foo&quot;, &quot;bar&quot;, &quot;foo&quot;, &quot;bar&quot;, &quot;foo&quot;, &quot;bar&quot;, &quot;foo&quot;, &quot;foo&quot;], &quot;B&quot; : [&quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;three&quot;, &quot;two&quot;, &quot;two&quot;, &quot;one&quot;, &quot;three&quot;], &quot;C&quot; : np.random.randn(8), &quot;D&quot; : np.random.randn(8)&#125;)df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D 0 foo one -0.714119 0.465098 1 bar one -1.100206 -0.224802 2 foo two -0.919036 -0.011397 3 bar three -0.383577 1.100142 4 foo two 1.012185 -0.492502 5 bar two 0.757571 0.043945 6 foo one 1.298525 1.664578 7 foo three -1.763909 -0.642626 그룹화 한 다음 sum() 결과 그룹에 함수를 적용합니다. 1df.groupby(&quot;A&quot;).sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; C D A bar -0.726212 0.919285 foo -1.086354 0.983151 여러 열로 그룹화하면 계층 적 색인이 형성되며 다시 sum()함수를 적용할 수 있습니다. 1df.groupby([&quot;A&quot;, &quot;B&quot;]).sum() .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; C D A B bar one -1.100206 -0.224802 three -0.383577 1.100142 two 0.757571 0.043945 foo one 0.584406 2.129676 three -1.763909 -0.642626 two 0.093150 -0.503899 재구성스택12345678910111213141516tuples = list( zip( *[ [&quot;bar&quot;, &quot;bar&quot;, &quot;baz&quot;, &quot;baz&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;qux&quot;, &quot;qux&quot;], [&quot;one&quot;, &quot;two&quot;, &quot;one&quot;, &quot;two&quot;, &quot;one&quot;, &quot;two&quot;, &quot;one&quot;, &quot;two&quot;], ] ))index = pd.MultiIndex.from_tuples(tuples, names=[&quot;first&quot;,&quot;second&quot;])df = pd.DataFrame(np.random.randn(8,2), index=index, columns=[&quot;A&quot;, &quot;B&quot;])df2 = df[:4]df2 .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B first second bar one -1.662320 0.032596 two -2.130549 -0.498520 baz one -1.052036 -0.809309 two -0.611723 -0.269502 이 stack()메소드는 DataFrame의 열에서 수준을 “압축”합니다. 123stacked = df2.stack()stacked first second bar one A -1.662320 B 0.032596 two A -2.130549 B -0.498520 baz one A -1.052036 B -0.809309 two A -0.611723 B -0.269502 dtype: float64 는 “누적”DataFrame 또는 직렬 (a 갖는 MultiIndex은 AS를 index중), 역 동작 stack()이다 unstack()기본적 unstacks, 최종 레벨 : 12345stacked.unstack()stacked.unstack(1)stacked.unstack(0) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; first bar baz second one A -1.662320 -1.052036 B 0.032596 -0.809309 two A -2.130549 -0.611723 B -0.498520 -0.269502 피벗 테이블123456789df = pd.DataFrame(&#123; &quot;A&quot;: [&quot;one&quot;, &quot;one&quot;, &quot;two&quot;, &quot;three&quot;] * 3, &quot;B&quot;: [&quot;A&quot;, &quot;B&quot;, &quot;C&quot;] * 4, &quot;C&quot;: [&quot;foo&quot;, &quot;foo&quot;, &quot;foo&quot;, &quot;bar&quot;, &quot;bar&quot;, &quot;bar&quot;] * 2, &quot;D&quot;: np.random.randn(12), &quot;E&quot;: np.random.randn(12)&#125;)df .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D E 0 one A foo 1.306726 -1.615560 1 one B foo -0.017440 -0.390718 2 two C foo -0.020291 -0.710189 3 three A bar -0.752024 -0.598660 4 one B bar -1.524553 -0.916927 5 one C bar 0.206644 0.784663 6 two A foo 1.864018 -0.087309 7 three B foo -1.175187 0.724690 8 one C foo 0.006408 0.313060 9 one A bar -0.174987 0.181471 10 two B bar 1.864114 0.835734 11 three C bar -0.788907 -0.686647 이 데이터에서 매우 쉽게 피벗 테이블을 생성할 수 있습니다. 1pd.pivot_table(df, values=&quot;D&quot;, index=[&quot;A&quot;, &quot;B&quot;], columns=[&quot;C&quot;]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; C bar foo A B one A -0.174987 1.306726 B -1.524553 -0.017440 C 0.206644 0.006408 three A -0.752024 NaN B NaN -1.175187 C -0.788907 NaN two A NaN 1.864018 B 1.864114 NaN C NaN -0.020291 시계열Pandas는 주파수 변환(예 : 2차 데이터를 5분 데이터로 변환) 중에 리샘플링 작업을 수행하기 위한 간단하고 강력하며 효율적인 기능을 제공합니다. 이는 금융 애플리케이션에서 매우 일반적이지만 이에 국한되지는 않습니다. 12345rng = pd.date_range(&quot;1/1/2012&quot;, periods=100, freq=&quot;S&quot;)ts = pd.Series(np.random.randint(0, 500, len(rng)), index=rng)ts.resample(&quot;5Min&quot;).sum() 2012-01-01 24059 Freq: 5T, dtype: int64 시간대 표현 : 123456789rng = pd.date_range(&quot;3/6/2012 00:00&quot;, periods=5, freq=&quot;D&quot;)ts = pd.Series(np.random.randn(len(rng)), rng)tsts_utc = ts.tz_localize(&quot;UTC&quot;)ts_utc 2012-03-06 00:00:00+00:00 0.244296 2012-03-07 00:00:00+00:00 -0.722339 2012-03-08 00:00:00+00:00 0.509596 2012-03-09 00:00:00+00:00 -0.530605 2012-03-10 00:00:00+00:00 -0.810000 Freq: D, dtype: float64 다른 시간대로 변환 : 1ts_utc.tz_convert(&quot;US/Eastern&quot;) 2012-03-05 19:00:00-05:00 0.244296 2012-03-06 19:00:00-05:00 -0.722339 2012-03-07 19:00:00-05:00 0.509596 2012-03-08 19:00:00-05:00 -0.530605 2012-03-09 19:00:00-05:00 -0.810000 Freq: D, dtype: float64 시간 범위 표현 간 변환 : 1234567891011rng = pd.date_range(&quot;1/1/2012&quot;, periods=5, freq=&quot;M&quot;)ts = pd.Series(np.random.randn(len(rng)), index=rng)tsps = ts.to_period()psps.to_timestamp() 2012-01-01 0.696409 2012-02-01 -0.801259 2012-03-01 0.236351 2012-04-01 0.249498 2012-05-01 -0.781067 Freq: MS, dtype: float64 기간과 타임 스탬프 사이를 변환하면 편리한 산술 함수를 사용할 수 있습니다. 다음 예에서는 연도가 11월로 끝나는 분기 별 빈도를 분기 종료 다음 달의 오전 9시로 변환합니다. 1234567prng = pd.period_range(&quot;1990Q1&quot;, &quot;2000Q4&quot;, freq=&quot;Q-NOV&quot;)ts = pd.Series(np.random.randn(len(prng)), prng)ts.index = (prng.asfreq(&quot;M&quot;, &quot;e&quot;)+1).asfreq(&quot;H&quot;, &quot;s&quot;) + 9ts.head() 1990-03-01 09:00 -0.982376 1990-06-01 09:00 1.155590 1990-09-01 09:00 -0.304843 1990-12-01 09:00 0.494812 1991-03-01 09:00 0.667193 Freq: H, dtype: float64 카테고리pandas는 DataFrame 123df = pd.DataFrame(&#123; &quot;id&quot;: [1, 2, 3, 4, 5, 6], &quot;raw_grade&quot;: [&quot;a&quot;, &quot;b&quot;, &quot;b&quot;, &quot;a&quot;, &quot;a&quot;, &quot;e&quot;]&#125;) 원시 성적을 범주 형 데이터 유형으로 변환합니다. 123df[&quot;grade&quot;] = df[&quot;raw_grade&quot;].astype(&quot;category&quot;)df[&quot;grade&quot;] 0 a 1 b 2 b 3 a 4 a 5 e Name: grade, dtype: category Categories (3, object): [&#39;a&#39;, &#39;b&#39;, &#39;e&#39;] 범주 이름을 보다 의미있는 이름으로 바꿉니다. 1df[&quot;grade&quot;].cat.categories = [&quot;very good&quot;, &quot;good&quot;, &quot;very bad&quot;] 범주를 재정렬하고 동시에 누락 된 범주를 추가합니다.(기본적으로 Series.cat() 새로운 방법을 반환하는 방법 Series) 12345df[&quot;grade&quot;] = df[&quot;grade&quot;].cat.set_categories( [&quot;very bad&quot;, &quot;bad&quot;, &quot;medium&quot;, &quot;good&quot;, &quot;very good&quot;])df[&quot;grade&quot;] 0 very good 1 good 2 good 3 very good 4 very good 5 very bad Name: grade, dtype: category Categories (5, object): [&#39;very bad&#39;, &#39;bad&#39;, &#39;medium&#39;, &#39;good&#39;, &#39;very good&#39;] 정렬은 어휘 순서가 아닌 범주의 순서에 따라 이루어집니다. 1df.sort_values(by=&quot;grade&quot;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; id raw_grade grade 5 6 e very bad 1 2 b good 2 3 b good 0 1 a very good 3 4 a very good 4 5 a very good 범주형 열로 그룹화하면 빈 범주도 표시됩니다. 1df.groupby(&quot;grade&quot;).size() grade very bad 1 bad 0 medium 0 good 2 very good 3 dtype: int64 플로팅matplotlib API를 참조하기 위해 표준 규칙을 사용합니다. 123import matplotlib.pyplot as pltplt.close(&quot;all&quot;) 12345ts = pd.Series(np.random.randn(1000), index=pd.date_range(&quot;1/1/2000&quot;, periods=1000))ts = ts.cumsum()ts.plot() &lt;matplotlib.axes._subplots.AxesSubplot at 0x7f8300728fd0&gt; DataFrame에서 이 plot()메소드는 레이블이 있는 모든 열을 표시하는데 편리합니다. 1234567891011df = pd.DataFrame( np.random.randn(1000,4), index=ts.index, columns=[&quot;A&quot;,&quot;B&quot;,&quot;C&quot;,&quot;D&quot;])df = df.cumsum()plt.figure()df.plot()plt.legend(loc=&#x27;best&#x27;) &lt;matplotlib.legend.Legend at 0x7f82ffc5f6d0&gt; &lt;Figure size 432x288 with 0 Axes&gt; 데이터 입출력CSVcsv파일에 쓰는 중 입니다. 1df.to_csv(&quot;foo.csv&quot;) csv파일에서 읽기 1pd.read_csv(&quot;foo.csv&quot;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Unnamed: 0 A B C D 0 2000-01-01 -0.946268 0.588085 -1.102185 -2.011696 1 2000-01-02 -0.940977 -0.645644 -2.615629 -2.244082 2 2000-01-03 0.448965 -0.183296 -2.437258 -3.986212 3 2000-01-04 -0.694449 -0.597946 -2.220138 -4.774340 4 2000-01-05 -0.909153 -0.200734 -2.831575 -5.637019 ... ... ... ... ... ... 995 2002-09-22 14.836307 -33.955098 -16.642909 -88.413076 996 2002-09-23 13.802744 -34.419502 -17.817695 -88.713839 997 2002-09-24 14.080196 -34.360305 -19.016304 -89.204070 998 2002-09-25 13.348737 -36.193934 -18.960392 -89.111542 999 2002-09-26 12.908612 -37.943369 -16.614981 -90.344603 1000 rows × 5 columns HDF5HDFStores 읽기 및 쓰기 HDF5 스토어에 쓰기 1df.to_hdf(&quot;foo.h5&quot;, &quot;df&quot;) HDF5스토어에서 읽기 1pd.read_hdf(&quot;foo.h5&quot;, &quot;df&quot;) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; A B C D 2000-01-01 -0.946268 0.588085 -1.102185 -2.011696 2000-01-02 -0.940977 -0.645644 -2.615629 -2.244082 2000-01-03 0.448965 -0.183296 -2.437258 -3.986212 2000-01-04 -0.694449 -0.597946 -2.220138 -4.774340 2000-01-05 -0.909153 -0.200734 -2.831575 -5.637019 ... ... ... ... ... 2002-09-22 14.836307 -33.955098 -16.642909 -88.413076 2002-09-23 13.802744 -34.419502 -17.817695 -88.713839 2002-09-24 14.080196 -34.360305 -19.016304 -89.204070 2002-09-25 13.348737 -36.193934 -18.960392 -89.111542 2002-09-26 12.908612 -37.943369 -16.614981 -90.344603 1000 rows × 4 columns 엑셀MS Excel 읽기 및 쓰기 엑셀파일에 쓰기 1df.to_excel(&quot;foo.xlsx&quot;, sheet_name=&quot;Sheet1&quot;) 엑셀 파일에서 읽기. 1pd.read_excel(&quot;foo.xlsx&quot;, &quot;Sheet1&quot;, index_col=None, na_values=[&quot;NA&quot;]) .dataframe tbody tr th:only-of-type { vertical-align: middle; } .dataframe tbody tr th &#123; vertical-align: top; &#125; .dataframe thead th &#123; text-align: right; &#125; Unnamed: 0 A B C D 0 2000-01-01 -0.946268 0.588085 -1.102185 -2.011696 1 2000-01-02 -0.940977 -0.645644 -2.615629 -2.244082 2 2000-01-03 0.448965 -0.183296 -2.437258 -3.986212 3 2000-01-04 -0.694449 -0.597946 -2.220138 -4.774340 4 2000-01-05 -0.909153 -0.200734 -2.831575 -5.637019 ... ... ... ... ... ... 995 2002-09-22 14.836307 -33.955098 -16.642909 -88.413076 996 2002-09-23 13.802744 -34.419502 -17.817695 -88.713839 997 2002-09-24 14.080196 -34.360305 -19.016304 -89.204070 998 2002-09-25 13.348737 -36.193934 -18.960392 -89.111542 999 2002-09-26 12.908612 -37.943369 -16.614981 -90.344603 1000 rows × 5 columns 고차작업을 수행하려는 경우 다음과 같은 예외가 표시될 수 있습니다. 12if pd.Series([False, True, False]): print(&quot;I was true&quot;) --------------------------------------------------------------------------- ValueError Traceback (most recent call last) &lt;ipython-input-140-5c782b38cd2f&gt; in &lt;module&gt;() ----&gt; 1 if pd.Series([False, True, False]): 2 print(&quot;I was true&quot;) /usr/local/lib/python3.7/dist-packages/pandas/core/generic.py in __nonzero__(self) 1328 def __nonzero__(self): 1329 raise ValueError( -&gt; 1330 f&quot;The truth value of a &#123;type(self).__name__&#125; is ambiguous. &quot; 1331 &quot;Use a.empty, a.bool(), a.item(), a.any() or a.all().&quot; 1332 ) ValueError: The truth value of a Series is ambiguous. Use a.empty, a.bool(), a.item(), a.any() or a.all().","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"시각화","slug":"시각화","date":"2021-04-07T14:02:07.000Z","updated":"2021-04-07T14:11:46.489Z","comments":true,"path":"2021/04/07/시각화/","link":"","permalink":"https://kjm94.github.io/2021/04/07/%EC%8B%9C%EA%B0%81%ED%99%94/","excerpt":"","text":"Matplotlib데이터 불러오기 123456789101112131415import matplotlib.pyplot as pltdates = [ &#x27;2021-01-01&#x27;, &#x27;2021-01-02&#x27;, &#x27;2021-01-03&#x27;, &#x27;2021-01-04&#x27;, &#x27;2021-01-05&#x27;, &#x27;2021-01-06&#x27;, &#x27;2021-01-07&#x27;, &#x27;2021-01-08&#x27;, &#x27;2021-01-09&#x27;, &#x27;2021-01-10&#x27;]min_temperature = [20.7, 17.9, 18.8, 14.6, 15.8, 15.8, 15.8, 17.4, 21.8, 20.0]max_temperature = [34.7, 28.9, 31.8, 25.6, 28.8, 21.8, 22.8, 28.4, 30.8, 32.0]fig,axes = plt.subplots(nrows=1, ncols=1, figsize = (10,6))axes.plot(dates, min_temperature, label = &#x27;Min Temperature&#x27;)axes.plot(dates, max_temperature, label = &#x27;Max Temperature&#x27;)axes.legend()plt.show() 12print(fig)print(axes) Figure(720x432) AxesSubplot(0.125,0.125;0.775x0.755) 선 그래프pyplot API123import fix_yahoo_finance as yfdata = yf.download(&#x27;AAPL&#x27;, &#x27;2019-08-01&#x27;, &#x27;2020-08-01&#x27;)data.info() [*********************100%***********************] 1 of 1 downloaded &lt;class &#39;pandas.core.frame.DataFrame&#39;&gt; DatetimeIndex: 253 entries, 2019-08-01 to 2020-07-31 Data columns (total 6 columns): # Column Non-Null Count Dtype --- ------ -------------- ----- 0 Open 253 non-null float64 1 High 253 non-null float64 2 Low 253 non-null float64 3 Close 253 non-null float64 4 Adj Close 253 non-null float64 5 Volume 253 non-null int64 dtypes: float64(5), int64(1) memory usage: 13.8 KB 12ts = data[&#x27;Open&#x27;]print(ts.head()) Date 2019-08-01 53.474998 2019-08-02 51.382500 2019-08-05 49.497501 2019-08-06 49.077499 2019-08-07 48.852501 Name: Open, dtype: float64 123456789101112import fix_yahoo_finance as yfimport matplotlib.pyplot as pltdata = yf.download(&#x27;AAPL&#x27;, &#x27;2019-08-01&#x27;,&#x27;2020-08-01&#x27;)ts = data[&#x27;Open&#x27;]plt.figure(figsize=(10,6))plt.plot(ts)plt.legend(labels=[&#x27;Price&#x27;], loc=&#x27;best&#x27;)plt.title(&#x27;Stock Market fluctuation of AAPL&#x27;)plt.xlabel(&#x27;Date&#x27;)plt.ylabel(&#x27;Stock Market Open Price&#x27;)plt.show() [*********************100%***********************] 1 of 1 downloaded 객체지향 API123456789101112from matplotlib.backends.backend_agg import FigureCanvasAgg as FigureCanvasfrom matplotlib.figure import Figurefig = Figure()import numpy as npnp.random.seed(6)x = np.random.randn(20000)ax = fig.add_subplot(111)ax.hist(x, 100)ax.set_title(&#x27;Artist Layer Histogram&#x27;)fig.savefig(&#x27;Matplotlib_histogram.png&#x27;) 1234567891011121314import fix_yahoo_finance as yfimport matplotlib.pyplot as pltdata = yf.download(&#x27;AAPL&#x27;, &#x27;2019-08-01&#x27;, &#x27;2020-08-01&#x27;)ts = data[&#x27;Open&#x27;]fig = plt.figure(figsize=(10,6)) # 직접 Figure 객체 생성ax = fig.subplots() # 직접 axes를 생성ax.plot(ts) # 생성된 axes에 대한 plot() 멤버 직접 호출ax.set_title(&#x27;Stock Market fluctuation of AAPL&#x27;)ax.legend(labels=[&#x27;Price&#x27;], loc=&#x27;best&#x27;)ax.set_xlabel(&#x27;Data&#x27;)ax.set_ylabel(&#x27;Stock Market Open Price&#x27;)plt.show() [*********************100%***********************] 1 of 1 downloaded 막대그래프12345678910111213141516171819import matplotlib.pyplot as pltimport numpy as npimport calendarmonth_list = [1,2,3,4,5,6,7,8,9,10,11,12]sold_list = [300,400,550,900,600,960,900,910,800,700,550,450]fig, ax = plt.subplots(figsize=(10,6))plot = ax.bar(month_list, sold_list)ax.set_xticks(month_list)ax.set_xticklabels(calendar.month_name[1:13], rotation=90)for rect in plot: print(rect) height = rect.get_height() ax.text(rect.get_x() + rect.get_width()/2., 1.002*height, &#x27;%d&#x27;% int(height), ha=&#x27;center&#x27;, va=&#x27;bottom&#x27;)plt.show() Rectangle(xy=(0.6, 0), width=0.8, height=300, angle=0) Rectangle(xy=(1.6, 0), width=0.8, height=400, angle=0) Rectangle(xy=(2.6, 0), width=0.8, height=550, angle=0) Rectangle(xy=(3.6, 0), width=0.8, height=900, angle=0) Rectangle(xy=(4.6, 0), width=0.8, height=600, angle=0) Rectangle(xy=(5.6, 0), width=0.8, height=960, angle=0) Rectangle(xy=(6.6, 0), width=0.8, height=900, angle=0) Rectangle(xy=(7.6, 0), width=0.8, height=910, angle=0) Rectangle(xy=(8.6, 0), width=0.8, height=800, angle=0) Rectangle(xy=(9.6, 0), width=0.8, height=700, angle=0) Rectangle(xy=(10.6, 0), width=0.8, height=550, angle=0) Rectangle(xy=(11.6, 0), width=0.8, height=450, angle=0) 산점도 그래프1234567891011121314import matplotlib.pyplot as pltimport seaborn as snstips = sns.load_dataset(&quot;tips&quot;)x = tips[&#x27;total_bill&#x27;]y = tips[&#x27;tip&#x27;]fig, ax = plt.subplots(figsize=(10,6))ax.scatter(x, y)ax.set_xlabel(&#x27;Total Bill&#x27;)ax.set_ylabel(&#x27;Tip&#x27;)ax.set_title(&#x27;Tip ~ Total Bill&#x27;)fig.show() 1label, data = tips.groupby(&#x27;sex&#x27;) 12345678910111213tips[&#x27;sex_color&#x27;] = tips[&#x27;sex&#x27;].map(&#123;&quot;Female&quot; : &quot;#0000FF&quot;, &quot;Male&quot; : &quot;#00FF00&quot;&#125;)fig, ax = plt.subplots(figsize=(10,6))for label, data in tips.groupby(&#x27;sex&#x27;): ax.scatter(data[&#x27;total_bill&#x27;], data[&#x27;tip&#x27;], label=label, color=data[&#x27;sex_color&#x27;], alpha=0.5) ax.set_xlabel(&#x27;Total Bill&#x27;) ax.set_ylabel(&#x27;Tip&#x27;) ax.set_title(&#x27;Tip ~ Total Bill by Gender&#x27;)ax.legend()fig.show() 히스토그램12345678910111213141516171819import matplotlib.pyplot as pltimport numpy as npimport seaborn as snstitanic = sns.load_dataset(&#x27;titanic&#x27;)age = titanic[&#x27;age&#x27;]nbins = 21fig, ax = plt.subplots(figsize=(10, 6))#histogramax.hist(age, bins= nbins)ax.set_xlabel(&quot;Age&quot;)ax.set_ylabel(&quot;Frequency&quot;)ax.set_title(&quot;Distribution of Aae in Titanic&quot;)#vlineax.axvline(x = age.mean(), linewidth = 2, color = &#x27;b&#x27;)fig.show() 박스플롯12345678910111213import matplotlib.pyplot as pltimport seaborn as snsiris = sns.load_dataset(&#x27;iris&#x27;)data = [iris[iris[&#x27;species&#x27;]==&#x27;setosa&#x27;][&#x27;petal_width&#x27;], iris[iris[&#x27;species&#x27;]==&#x27;versicolor&#x27;][&#x27;petal_width&#x27;], iris[iris[&#x27;species&#x27;]==&#x27;virginica&#x27;][&#x27;petal_width&#x27;],]fig, ax = plt.subplots(figsize=(10,6))ax.boxplot(data, labels=[&#x27;setosa&#x27;, &#x27;versicolor&#x27;, &#x27;virginica&#x27;])fig.show() 히트맵123456789101112131415import matplotlib.pyplot as pltimport numpy as npimport seaborn as snsflights = sns.load_dataset(&#x27;flights&#x27;)flights = flights.pivot(&quot;month&quot;,&quot;year&quot;,&quot;passengers&quot;)print(flights)fig, ax = plt.subplots(figsize=(12,6))im = ax.imshow(flights, cmap = &#x27;YlGnBu&#x27;)ax.set_xticklabels(flights.columns, rotation = 20)ax.set_yticklabels(flights.index, rotation = 10)fig.colorbar(im)fig.show() year 1949 1950 1951 1952 1953 1954 1955 1956 1957 1958 1959 1960 month Jan 112 115 145 171 196 204 242 284 315 340 360 417 Feb 118 126 150 180 196 188 233 277 301 318 342 391 Mar 132 141 178 193 236 235 267 317 356 362 406 419 Apr 129 135 163 181 235 227 269 313 348 348 396 461 May 121 125 172 183 229 234 270 318 355 363 420 472 Jun 135 149 178 218 243 264 315 374 422 435 472 535 Jul 148 170 199 230 264 302 364 413 465 491 548 622 Aug 148 170 199 242 272 293 347 405 467 505 559 606 Sep 136 158 184 209 237 259 312 355 404 404 463 508 Oct 119 133 162 191 211 229 274 306 347 359 407 461 Nov 104 114 146 172 180 203 237 271 305 310 362 390 Dec 118 140 166 194 201 229 278 306 336 337 405 432","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"List and tuple","slug":"List-and-tuple","date":"2021-04-06T03:19:17.000Z","updated":"2021-04-07T12:41:36.733Z","comments":true,"path":"2021/04/06/List-and-tuple/","link":"","permalink":"https://kjm94.github.io/2021/04/06/List-and-tuple/","excerpt":"","text":"리스트와 튜플12list = [1, 2, &quot;a&quot;, 3, 4] # 리스트의 형태tuple = (5, 6, &quot;b&quot;, 7, 8) # 튜플의 형태 두 타입 모두 요소의 순서를 관리하지만 기술적으로 유일한 차이점이 있다. 리스트는 가변(mutable)성 튜플은 불변(immutable)성 즉 튜플은 append, insert, expend, remove, del, pop 등의 함수를 통해 기존의 자료를 변경할 수 없음. 리스트는 튜플에 비해 더 많은 공간을 저장해둔다. 리스트는 딕셔너리의 key값으로 사용할 수 없지만 튜플은 가능하다. 다루는 자료가 다른 길이의 데이터를 갖는다면 리스트를 사용한다. 함수형 프로그래밍에서는 코드가 어려워 질 수 있는 부작용을 피하기 위해불변 데이터를 사용하는 것을 권장한다.","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"컴퓨터 공학 입문 수료증","slug":"컴퓨터-공학-입문-수료증","date":"2021-04-04T13:30:59.000Z","updated":"2021-04-06T13:42:21.673Z","comments":true,"path":"2021/04/04/컴퓨터-공학-입문-수료증/","link":"","permalink":"https://kjm94.github.io/2021/04/04/%EC%BB%B4%ED%93%A8%ED%84%B0-%EA%B3%B5%ED%95%99-%EC%9E%85%EB%AC%B8-%EC%88%98%EB%A3%8C%EC%A6%9D/","excerpt":"","text":"1단계 수료증https://pabi.smartlearn.io/certificates/92e0f41b4f52411faa9a6d9223a5e2eb 2단계 수료증https://pabi.smartlearn.io/certificates/f62ff5faca5c4557a5c0f502c9184b9e","categories":[],"tags":[{"name":"C","slug":"C","permalink":"https://kjm94.github.io/tags/C/"}]},{"title":"R 데이터 정리, 시각화 연습 코드","slug":"R-데이터-정리-시각화-연습-코드","date":"2021-04-03T04:23:08.000Z","updated":"2021-04-03T04:23:24.637Z","comments":true,"path":"2021/04/03/R-데이터-정리-시각화-연습-코드/","link":"","permalink":"https://kjm94.github.io/2021/04/03/R-%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%A0%95%EB%A6%AC-%EC%8B%9C%EA%B0%81%ED%99%94-%EC%97%B0%EC%8A%B5-%EC%BD%94%EB%93%9C/","excerpt":"","text":"참고 사이트http://www.sthda.com/english/wiki/descriptive-statistics-and-graphics","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"Data Swap","slug":"Data-Swap","date":"2021-04-01T00:08:34.000Z","updated":"2021-04-06T13:42:21.670Z","comments":true,"path":"2021/04/01/Data-Swap/","link":"","permalink":"https://kjm94.github.io/2021/04/01/Data-Swap/","excerpt":"","text":"데이터 변환 각 데이터 타입별로 변수에 저장된 값을 서로 바꾼다. 123456789101112131415161718192021222324252627282930#include &lt;iostream&gt;using namespace std;template&lt;typename SwapData&gt;void Swap(SwapData&amp; num1, SwapData&amp; num2)&#123; SwapData temp = num1; num1 = num2; num2 = temp;&#125;int main()&#123; int num1 = 2, num2 = 4; double num3 = 1.14, num4 = 3.57; cout &lt;&lt; &quot;스왑이전, num1 : &quot; &lt;&lt; num1 &lt;&lt; &quot;, num2 : &quot; &lt;&lt; num2 &lt;&lt; endl; Swap(num1, num2); cout &lt;&lt; &quot;스왑이후, num1 : &quot; &lt;&lt; num1 &lt;&lt; &quot;, num2 : &quot; &lt;&lt; num2 &lt;&lt; endl; cout &lt;&lt; &quot;스왑이전, num3 : &quot; &lt;&lt; num3 &lt;&lt; &quot;, num4 : &quot; &lt;&lt; num4 &lt;&lt; endl; Swap(num3, num4); cout &lt;&lt; &quot;스왑이후, num3 : &quot; &lt;&lt; num3 &lt;&lt; &quot;, num4 : &quot; &lt;&lt; num4 &lt;&lt; endl; return 0;&#125;","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://kjm94.github.io/tags/C/"}]},{"title":"미등록 패키지 연동","slug":"미등록-패패키지-연동","date":"2021-03-31T05:03:59.000Z","updated":"2021-04-03T04:13:59.491Z","comments":true,"path":"2021/03/31/미등록-패패키지-연동/","link":"","permalink":"https://kjm94.github.io/2021/03/31/%EB%AF%B8%EB%93%B1%EB%A1%9D-%ED%8C%A8%ED%8C%A8%ED%82%A4%EC%A7%80-%EC%97%B0%EB%8F%99/","excerpt":"","text":"12345678910111213141516171819if(!require(remotes))&#123; install.packages(&#x27;remotes&#x27;)&#125; # remotes 가져오는 함수remotes::install_github(&quot;profandyfield/discovr&quot;)# 설치되지 않는 경우.libPaths() # 위치확인 함수로 확인remotes::install_github(&quot;profandyfield/discovr&quot;, lib = &quot;N:/Documents/R/win-library/3.5&quot;) # 본인 위치 입력library(discovr) # 라이브러리 등록learnr::run_tutorial(&quot;name_of_tutorial&quot;, package = &quot;discovr&quot;) # 해당 패키지의 튜토리얼 등록learnr::run_tutorial(&quot;discovr_02&quot;, package = &quot;discovr&quot;) # 튜토리얼 페이지 실행","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"데이터 사이언스를 위한 통계학입문 수료증","slug":"데이터-사이언스를-위한-통e¼계학입문-수료증","date":"2021-03-31T00:09:02.000Z","updated":"2021-04-03T04:13:59.488Z","comments":true,"path":"2021/03/31/데이터-사이언스를-위한-통e¼계학입문-수료증/","link":"","permalink":"https://kjm94.github.io/2021/03/31/%EB%8D%B0%EC%9D%B4%ED%84%B0-%EC%82%AC%EC%9D%B4%EC%96%B8%EC%8A%A4%EB%A5%BC-%EC%9C%84%ED%95%9C-%ED%86%B5e%C2%BC%EA%B3%84%ED%95%99%EC%9E%85%EB%AC%B8-%EC%88%98%EB%A3%8C%EC%A6%9D/","excerpt":"","text":"1단계 수료증https://pabi.smartlearn.io/certificates/45cd0c85f0364738a196e75de7f1b456 2단계 수료증https://pabi.smartlearn.io/certificates/41b3e499fd7745b3bcbc62b8592793e5","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"overriding","slug":"overriding","date":"2021-03-28T05:34:16.000Z","updated":"2021-04-03T04:13:59.487Z","comments":true,"path":"2021/03/28/overriding/","link":"","permalink":"https://kjm94.github.io/2021/03/28/overriding/","excerpt":"","text":"함수 오버라이딩 개와 고양이 클래스를 따로 생성하여 동물 클래스에 상속받기 울음소리를 오버라이딩 1234567891011121314151617181920212223242526272829303132333435363738394041424344#include &lt;iostream&gt;using namespace std;class Animal&#123;public: void cry() &#123; cout &lt;&lt; &quot;짖는소리&quot; &lt;&lt; endl; &#125;&#125;;class Dog : public Animal&#123;public: void cry() &#123; cout &lt;&lt; &quot;개짖는소리 왈왈&quot; &lt;&lt; endl; &#125;&#125;;class Cat : public Animal&#123;public: void cry() &#123; cout &lt;&lt; &quot;고양이 짖는소리 냐옹&quot; &lt;&lt; endl; &#125;&#125;;int main()&#123; Dog d; Cat c; d.cry(); c.cry(); return 0;&#125;","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://kjm94.github.io/tags/C/"}]},{"title":"Random Game 2","slug":"Random-Game-2","date":"2021-03-27T10:56:19.000Z","updated":"2021-04-03T04:13:59.483Z","comments":true,"path":"2021/03/27/Random-Game-2/","link":"","permalink":"https://kjm94.github.io/2021/03/27/Random-Game-2/","excerpt":"","text":"동전 던지기 게임랜덤 함수 활용 1을 입력하면 앞면과 뒷면 중 랜덤하게 출력 0을 입력하면 종료 외 숫자 입력 시 예외출력 123456789101112131415161718192021222324252627282930313233343536373839404142434445464748495051#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;random&gt;using namespace std;int main()&#123; int Coin; random_device rd; mt19937 gen(rd()); uniform_int_distribution&lt;int&gt; dis(0, 1); string com_out; while (1) &#123; int com = dis(gen); cout &lt;&lt; &quot;동전던지기 시작(1) 종료(0)&quot; &lt;&lt; endl; cin &gt;&gt; Coin; if (Coin == 0) &#123; cout &lt;&lt; &quot;종료&quot; &lt;&lt; endl; break; &#125; else if (Coin == 1) &#123; // 시작 if (com == 0) &#123; cout &lt;&lt; &quot;뒷면&quot; &lt;&lt; endl; &#125; else if (com == 1) &#123; cout &lt;&lt; &quot;앞면&quot; &lt;&lt; endl; &#125; &#125; else &#123; cout &lt;&lt; &quot;0과 1의 숫자로 다시 시도하세요.&quot; &lt;&lt; endl; &#125; &#125; return 0;&#125;","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://kjm94.github.io/tags/C/"}]},{"title":"datacamp","slug":"datacamp","date":"2021-03-26T12:58:34.000Z","updated":"2021-03-26T13:00:07.814Z","comments":true,"path":"2021/03/26/datacamp/","link":"","permalink":"https://kjm94.github.io/2021/03/26/datacamp/","excerpt":"","text":"##R 코딩 연습 R 코딩이 어렵다고 생각하여 연습하기 위해 datacamp 링크 저장 https://www.datacamp.com/users/sign_in?redirect=https%3A%2F%2Flearn.datacamp.com%2Fcourses","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"","slug":"marprac","date":"2021-03-26T12:53:13.614Z","updated":"2021-03-26T12:53:13.615Z","comments":true,"path":"2021/03/26/marprac/","link":"","permalink":"https://kjm94.github.io/2021/03/26/marprac/","excerpt":"","text":"House prices: Lasso, XGBoost, and a detailed EDA h1 {font-size: 34px;} h1.title {font-size: 38px;} h2 {font-size: 30px;} h3 {font-size: 24px;} h4 {font-size: 18px;} h5 {font-size: 16px;} h6 {font-size: 12px;} code {color: inherit; background-color: rgba(0, 0, 0, 0.04);} pre:not([class]) { background-color: white } code{white-space: pre-wrap;} span.smallcaps{font-variant: small-caps;} span.underline{text-decoration: underline;} div.column{display: inline-block; vertical-align: top; width: 50%;} div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;} ul.task-list{list-style: none;} code{white-space: pre;} if (window.hljs) { hljs.configure({languages: []}); hljs.initHighlightingOnLoad(); if (document.readyState && document.readyState === \"complete\") { window.setTimeout(function() { hljs.initHighlighting(); }, 0); } } .main-container { max-width: 940px; margin-left: auto; margin-right: auto; } img { max-width:100%; } .tabbed-pane { padding-top: 12px; } .html-widget { margin-bottom: 20px; } button.code-folding-btn:focus { outline: none; } summary { display: list-item; } pre code { padding: 0; } .tabset-dropdown > .nav-tabs { display: inline-table; max-height: 500px; min-height: 44px; overflow-y: auto; border: 1px solid #ddd; border-radius: 4px; } .tabset-dropdown > .nav-tabs > li.active:before { content: \"\"; font-family: 'Glyphicons Halflings'; display: inline-block; padding: 10px; border-right: 1px solid #ddd; } .tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before { content: \"\"; border: none; } .tabset-dropdown > .nav-tabs.nav-tabs-open:before { content: \"\"; font-family: 'Glyphicons Halflings'; display: inline-block; padding: 10px; border-right: 1px solid #ddd; } .tabset-dropdown > .nav-tabs > li.active { display: block; } .tabset-dropdown > .nav-tabs > li > a, .tabset-dropdown > .nav-tabs > li > a:focus, .tabset-dropdown > .nav-tabs > li > a:hover { border: none; display: inline-block; border-radius: 4px; background-color: transparent; } .tabset-dropdown > .nav-tabs.nav-tabs-open > li { display: block; float: none; } .tabset-dropdown > .nav-tabs > li { display: none; } House prices: Lasso, XGBoost, and a detailed EDA Kwon jung min 1 Loading and Exploring Data #요약 저는 데이터 세트를 잘 이해하는 데 집중하면서이 대회를 시작했습니다. EDA는 상세하며 많은 시각화가 포함되어 있습니다. 이 버전에는 모델링도 포함됩니다. Lasso 회귀는 교차 검증 RMSE 점수가 0.1121 일 때 가장 잘 수행됩니다. 변수들 사이에 많은 다중 공선 성이 있다는 사실을 감안할 때 이것은 예상되었습니다. Lasso는 예상대로 모델에서 사용 가능한 많은 변수를 선택하지 않습니다. XGBoost 모델은 교차 검증 RMSE가 0.1162로 매우 잘 수행됩니다. *이 두 알고리즘은 매우 다르기 때문에 평균 예측은 예측을 향상시킬 수 있습니다. Lasso 교차 검증 RMSE가 XGBoost의 CV 점수보다 낫기 때문에 Lasso 결과에 두 배의 가중치를 부여하기로 결정했습니다. #Introduction Kaggle은 이 경쟁을 다음과 같이 설명합니다. follows: 주택 구입자에게 꿈의 집을 설명해달라고 요청하면 지하 천장 높이나 동서 철도와의 근접성으로 시작하지 않을 것입니다. 그러나이 놀이터 대회의 데이터 세트는 침실 수나 흰둥이 울타리보다 가격 협상에 훨씬 더 많은 영향을 미친다는 것을 증명합니다. 아이오와 주 에임스에있는 주거용 주택의 거의 모든 측면을 설명하는 79 개의 설명 변수가있는이 경쟁에서는 각 주택의 최종 가격을 예측해야합니다. 1 Loading and Exploring Data ##Loading libraries required and reading the data into R 기본 R 외에 사용되는 R 패키지를로드합니다. # 메세지와 경고를 출력하지 않는다. (반대 : TRUE) library(knitr) # 동적 보고서 생성 엔진 참고 URL : https://en.wikipedia.org/wiki/Knitr library(ggplot2) # 데이터 시각화 패키지 library(plyr) # 데이터 분할, 적용, 조합의 세단계로 데이터를 처리하는 함수 제공 (배열, 데이터 프레임, 리스트) 참고 URL : https://data-make.tistory.com/59 library(dplyr) # 데이터 전처리, 가공 library(corrplot) # 상관행렬과 신뢰구간의 그래프, 행렬의 재정렬 알고리즘 포함 패키지 참고 URL : https://rpubs.com/cardiomoon/27080 library(caret) # 복잡한 회귀와 분류 문제에 대한 모형 훈련과 조절과정을 간소화 하는 함수 참고 URL : http://kocw-n.xcache.kinxcdn.com/data/document/2017/chungbuk/najonghwa/8.pdf library(gridExtra) # 차트 분할 출력 library(scales) # 시각적 맵핑 library(Rmisc) # 데이터 분석 및 유틸리티에 유용한 함수 모음 library(ggrepel) # 레이블 정리 참고 URL : https://kuduz.tistory.com/1111 library(randomForest) # 랜덤으로 만들어 나온 결과를 투표방식으로 예측하는 알고리즘 참고 URL : https://hongsamm.tistory.com/20 library(psych) # 기술통계량을 제공하는 함수 중 하나 참고 URL : https://dr-hkim.github.io/R-301-Descriptive-Statistics/ library(xgboost) # 병렬처리 최적화 패키지 상관행렬 : 확률론과 통계학에서 두 변수간에 어떤 선형적 관계를 갖고 있는 지를 분석하는 방법 신뢰구간 : 표본평균 분포 병렬처리 : 동시에 많은 계산을 하는 연산의 방법 참고URL : https://ko.wikipedia.org/wiki/%EB%B3%91%EB%A0%AC_%EC%BB%B4%ED%93%A8%ED%8C%85 아래에서는 csv를 데이터 프레임으로 R로 읽고 있습니다. train &lt;- read.csv(&quot;train.csv&quot;, stringsAsFactors = F) # 데이터를 R로 불러오지만 메모리에 저장되는 것은 아님 stringsAsFactors : 데이터를 불러올 때, 데이터에 숫자 외의 데이터로 인한 오류 방지 ##데이터 크기 및 구조 train 데이터 세트는 문자 및 정수 변수로 구성됩니다. 대부분의 문자 변수는 실제로 (순서적인) 요인이지만 대부분의 경우 정리 및 / 또는 기능 엔지니어링이 먼저 필요하기 때문에 문자열로 R로 읽기로 선택했습니다. 총 81 개의 열 / 변수가 있으며 마지막 열은 반응 변수 (SalePrice)입니다. 아래에서는 변수를 간략하게 보여주고 있습니다. 그들 모두는 문서 전체에서 더 자세히 논의됩니다. #ID를 제거하지만 테스트 ID를 벡터에 유지합니다. 제출 파일을 작성하는 데 필요합니다. train$Id &lt;- NULL all &lt;- rbind(train) # rbind : 데이터 결합 dim(all) # 데이터프레임 의 길이 관측, 행과 열의 갯수를 출력 ## [1] 1460 80 ID가 없으면 데이터 프레임은 79 개의 예측 변수와 응답 변수 SalePrice로 구성됩니다. #Exploring some of the most important variables ##반응 변수; SalePrice 보시다시피 판매 가격이 올바르게 왜곡되어 있습니다. 이것은 매우 비싼 집을 살 수있는 사람이 거의 없기 때문에 예상되었습니다. 이를 염두에두고 모델링 전에 조치를 취하겠습니다. ggplot(data=all[!is.na(all$SalePrice),], aes(x=SalePrice)) + geom_histogram(fill=&quot;blue&quot;, binwidth = 10000) + scale_x_continuous(breaks= seq(0, 800000, by=100000), labels = comma) binwidth : 연속형 변수를 일정한 구간으로 나누어 빈도수를 구한 후 막대 그래프로 표현 summary(all$SalePrice) # 기술통계 함수 참고 URL : http://blog.naver.com/PostView.nhn?blogId=rickman2&amp;logNo=221451645853&amp;categoryNo=40&amp;parentCategoryNo=0 ## Min. 1st Qu. Median Mean 3rd Qu. Max. ## 34900 129975 163000 180921 214000 755000 ##가장 중요한 숫자 예측 변수 문자 변수를 사용하려면 작업이 필요합니다. 데이터 세트에 대한 느낌을 얻기 위해 먼저 SalePrice와 높은 상관 관계가있는 숫자 변수를 확인하기로 결정했습니다. ###SalePrice와의 상관 관계 전체적으로 SalePrice와 최소 0.5의 상관 관계가있는 10 개의 숫자 변수가 있습니다. 이러한 모든 상관 관계는 긍정적입니다. numericVars &lt;- which(sapply(all, is.numeric)) #인덱스 벡터 숫자 형 변수 numericVarNames &lt;- names(numericVars) #나중에 사용하기 위해 names 벡터 저장 cat(&#39;There are&#39;, length(numericVars), &#39;numeric variables&#39;) ## There are 37 numeric variables # which : 특정 값의 위치를 찾는 함수 찾고자 하는 값의 위치를 반환 all_numVar &lt;- all[, numericVars] cor_numVar &lt;- cor(all_numVar, use=&quot;pairwise.complete.obs&quot;) #모든 숫자 변수의 상관 관계 #SalePrice와의 감소하는 상관 관계에 따라 정렬 cor_sorted &lt;- as.matrix(sort(cor_numVar[,&#39;SalePrice&#39;], decreasing = TRUE)) #높은 corelations 만 선택 CorHigh &lt;- names(which(apply(cor_sorted, 1, function(x) abs(x)&gt;0.5))) cor_numVar &lt;- cor_numVar[CorHigh, CorHigh] corrplot.mixed(cor_numVar, tl.col=&quot;black&quot;, tl.pos = &quot;lt&quot;) 이 섹션의 나머지 부분에서는 SalePrice와 SalePrice와 가장 높은 상관 관계를 가진 두 예측 변수 간의 관계를 시각화합니다. 전반적인 품질 및 ’고급’생활 공간 (이것은 지하실에없는 집의 비율입니다. link). 또한 다중 공선 성이 문제라는 것이 분명해집니다. 예를 들어, GarageCars와 GarageArea 간의 상관 관계는 매우 높고 (0.89) 둘 다 SalePrice와 유사한 (높은) 상관 관계를가집니다. SalePrice와의 상관 관계가 0.5보다 높은 나머지 6 개의 변수는 다음과 같습니다.: -TotalBsmtSF: 지하 총 평방 피트 -1stFlrSF: 1 층 평방 피트 -FullBath: 욕실 포함 등급 이상의 방 -TotRmsAbvGrd: 등급 이상의 총 방 (욕실은 포함되지 않음) -YearBuilt: 원래 건설 날짜 -YearRemodAdd: 리모델링 날짜 (개조 또는 추가가없는 경우 건설 날짜와 동일) ###전반적인 품질 전체 품질은 수치 변수 (0.79) 중 SalePrice와 가장 높은 상관 관계를 나타냅니다. 집의 전체 재료와 마감을 1 (매우 나쁨)에서 10 (매우 우수)까지 등급으로 평가합니다. ggplot(data=all[!is.na(all$SalePrice),], aes(x=factor(OverallQual), y=SalePrice))+ geom_boxplot(col=&#39;blue&#39;) + labs(x=&#39;Overall Quality&#39;) + scale_y_continuous(breaks= seq(0, 800000, by=100000), labels = comma) 양의 상관 관계는 확실히 존재하며 약간 상승 곡선 인 것 같습니다. 특이 치에 관해서는 극단적 인 값이 보이지 않습니다. 나중에 이상치로 빼낼 후보가 있으면 4 급 고가 집 인 것 같다. ###지상 (지상) 거실 공간 (평방 피트) SalesPrice와 두 번째로 높은 상관 관계가있는 숫자 변수는 Grade Living Area입니다. 이것은 많은 의미가 있습니다. 큰 집은 일반적으로 더 비쌉니다. ggplot(data=all[!is.na(all$SalePrice),], aes(x=GrLivArea, y=SalePrice))+ geom_point(col=&#39;blue&#39;) + geom_smooth(method = &quot;lm&quot;, se=FALSE, color=&quot;black&quot;, aes(group=1)) + scale_y_continuous(breaks= seq(0, 800000, by=100000), labels = comma) + geom_text_repel(aes(label = ifelse(all$GrLivArea[!is.na(all$SalePrice)]&gt;4500, rownames(all), &#39;&#39;))) ## Warning: Use of `all$GrLivArea` is discouraged. Use `GrLivArea` instead. ## Warning: Use of `all$SalePrice` is discouraged. Use `SalePrice` instead. ## `geom_smooth()` using formula &#39;y ~ x&#39; rownames : 행 이름을 바꾸는 함수 특히 거실이 넓고 SalePrices가 낮은 두 주택은 이상치처럼 보입니다 (주택 524 및 1299, 그래프의 레이블 참조). 이상 값을 가져 오는 것은 위험 할 수 있으므로 아직 제거하지 않겠습니다. 예를 들어, 전반적인 품질에서 낮은 점수는 낮은 가격을 설명 할 수 있습니다. 그러나 아래에서 볼 수 있듯이 이 두 주택은 실제로 전체 품질에서 최대 점수를 얻습니다. 따라서 저는 1299 호와 524 호를 이상 값으로 제거 할 주요 후보로 염두에 두겠습니다. all[c(524, 1299), c(&#39;SalePrice&#39;, &#39;GrLivArea&#39;, &#39;OverallQual&#39;)] ## SalePrice GrLivArea OverallQual ## 524 184750 4676 10 ## 1299 160000 5642 10 #누락 된 데이터, 레이블 인코딩 및 변수 분해 ##데이터의 완전성 우선, 어떤 변수에 결 측값이 있는지 확인하고 싶습니다. NAcol &lt;- which(colSums(is.na(all)) &gt; 0) sort(colSums(sapply(all[NAcol], is.na)), decreasing = TRUE) ## PoolQC MiscFeature Alley Fence FireplaceQu LotFrontage ## 1453 1406 1369 1179 690 259 ## GarageType GarageYrBlt GarageFinish GarageQual GarageCond BsmtExposure ## 81 81 81 81 81 38 ## BsmtFinType2 BsmtQual BsmtCond BsmtFinType1 MasVnrType MasVnrArea ## 38 37 37 37 8 8 ## Electrical ## 1 sort : 숫자 자체 정렬 decreasing : 내림차순 cat(&#39;There are&#39;, length(NAcol), &#39;columns with missing values&#39;) ## There are 19 columns with missing values cat : 개행을 하지 않는 출력함수 물론 SalePrice의 1459 NA는 테스트 세트의 크기와 완벽하게 일치합니다. 이는 34 개의 예측 변수에서 NA를 수정해야 함을 의미합니다. ##누락 된 데이터 {.tabset} 대치 이 섹션에서는 결 측값이 포함 된 34 개의 예측 변수를 수정하겠습니다. 나는 그것들을 모두 고칠 때까지 대부분의 NA에서 내려가는 방법을 살펴볼 것입니다. 실제로 다른 변수와 그룹을 형성하는 변수를 우연히 발견하면 그룹으로 다룰 것입니다. 예를 들어, 수영장, 차고 및 지하와 관련된 여러 변수가 있습니다. 문서를 가능한 한 읽기 쉽게 유지하기 위해 knitr에서 제공하는 “Tabs”옵션을 사용하기로 결정했습니다. 각 탭 아래에서 각 변수 (그룹)에 대한 간단한 분석을 찾을 수 있습니다. 모든 섹션을 살펴볼 필요는 없으며 몇 개의 탭만 볼 수도 있습니다. 그렇게한다면, 저는 지하실이나 차고가없는 집을 신중하게 결정했기 때문에 특히 차고와 지하실 섹션이 가치가 있다고 생각합니다. NA가 제거되었는지 확인하는 것 외에도, 명확한 순서가있는 경우 문자 변수를 순서 형 정수로 변환하고 수준이 순서 성이없는 범주 인 경우 요인으로 변환했습니다. 나중에 원-핫 인코딩 (model.matrix 함수 사용)을 사용하여 이러한 요소를 숫자로 변환합니다. ###Pool variables Pool Quality and the PoolArea variable PoolQC는 대부분의 NA가있는 변수입니다. 설명은 다음과 같습니다: PoolQC: Pool quality Ex Excellent Gd Good TA Average/Typical Fa Fair NA No Pool 따라서 NA에 ’No Pool’만 할당하면됩니다. 또한 일반적으로 소수의 주택에만 수영장이 있기 때문에 많은 수의 NA가 의미가 있습니다. all$PoolQC[is.na(all$PoolQC)] &lt;- &#39;None&#39; 값이 서수이므로 이 변수에 레이블을 인코딩 할 수 있다는 것도 분명합니다. 동일한 품질 수준을 사용하는 여러 변수가 있으므로 나중에 다시 사용할 수있는 벡터를 만들 것입니다. Qualities &lt;- c(&#39;None&#39; = 0, &#39;Po&#39; = 1, &#39;Fa&#39; = 2, &#39;TA&#39; = 3, &#39;Gd&#39; = 4, &#39;Ex&#39; = 5) 이제 ’revalue’기능을 사용하여 작업을 수행 할 수 있습니다. all$PoolQC&lt;-as.integer(revalue(all$PoolQC, Qualities)) table(all$PoolQC) ## ## 0 2 4 5 ## 1453 2 3 2 revalue : plyr 패키지 안의 라벨 변경 함수 // add bootstrap table styles to pandoc tables function bootstrapStylePandocTables() { $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed'); } $(document).ready(function () { bootstrapStylePandocTables(); }); $(document).ready(function () { window.buildTabsets(\"TOC\"); }); $(document).ready(function () { $('.tabset-dropdown > .nav-tabs > li').click(function () { $(this).parent().toggleClass('nav-tabs-open'); }); }); (function () { var script = document.createElement(\"script\"); script.type = \"text/javascript\"; script.src = \"https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"; document.getElementsByTagName(\"head\")[0].appendChild(script); })();","categories":[],"tags":[]},{"title":"","slug":"mark1","date":"2021-03-26T12:53:13.606Z","updated":"2021-03-26T12:53:13.607Z","comments":true,"path":"2021/03/26/mark1/","link":"","permalink":"https://kjm94.github.io/2021/03/26/mark1/","excerpt":"","text":"My 1st MarkDown h1 {font-size: 34px;} h1.title {font-size: 38px;} h2 {font-size: 30px;} h3 {font-size: 24px;} h4 {font-size: 18px;} h5 {font-size: 16px;} h6 {font-size: 12px;} code {color: inherit; background-color: rgba(0, 0, 0, 0.04);} pre:not([class]) { background-color: white } code{white-space: pre-wrap;} span.smallcaps{font-variant: small-caps;} span.underline{text-decoration: underline;} div.column{display: inline-block; vertical-align: top; width: 50%;} div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;} ul.task-list{list-style: none;} code{white-space: pre;} if (window.hljs) { hljs.configure({languages: []}); hljs.initHighlightingOnLoad(); if (document.readyState && document.readyState === \"complete\") { window.setTimeout(function() { hljs.initHighlighting(); }, 0); } } .main-container { max-width: 940px; margin-left: auto; margin-right: auto; } img { max-width:100%; } .tabbed-pane { padding-top: 12px; } .html-widget { margin-bottom: 20px; } button.code-folding-btn:focus { outline: none; } summary { display: list-item; } pre code { padding: 0; } .tabset-dropdown > .nav-tabs { display: inline-table; max-height: 500px; min-height: 44px; overflow-y: auto; border: 1px solid #ddd; border-radius: 4px; } .tabset-dropdown > .nav-tabs > li.active:before { content: \"\"; font-family: 'Glyphicons Halflings'; display: inline-block; padding: 10px; border-right: 1px solid #ddd; } .tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before { content: \"\"; border: none; } .tabset-dropdown > .nav-tabs.nav-tabs-open:before { content: \"\"; font-family: 'Glyphicons Halflings'; display: inline-block; padding: 10px; border-right: 1px solid #ddd; } .tabset-dropdown > .nav-tabs > li.active { display: block; } .tabset-dropdown > .nav-tabs > li > a, .tabset-dropdown > .nav-tabs > li > a:focus, .tabset-dropdown > .nav-tabs > li > a:hover { border: none; display: inline-block; border-radius: 4px; background-color: transparent; } .tabset-dropdown > .nav-tabs.nav-tabs-open > li { display: block; float: none; } .tabset-dropdown > .nav-tabs > li { display: none; } My 1st MarkDown R Markdown This is an R Markdown document. Markdown is a simple formatting syntax for authoring HTML, PDF, and MS Word documents. For more details on using R Markdown see http://rmarkdown.rstudio.com. When you click the Knit button a document will be generated that includes both content as well as the output of any embedded R code chunks within the document. You can embed an R code chunk like this: summary(cars) ## speed dist ## Min. : 4.0 Min. : 2.00 ## 1st Qu.:12.0 1st Qu.: 26.00 ## Median :15.0 Median : 36.00 ## Mean :15.4 Mean : 42.98 ## 3rd Qu.:19.0 3rd Qu.: 56.00 ## Max. :25.0 Max. :120.00 Including Plots You can also embed plots, for example: Note that the echo = FALSE parameter was added to the code chunk to prevent printing of the R code that generated the plot. // add bootstrap table styles to pandoc tables function bootstrapStylePandocTables() { $('tr.odd').parent('tbody').parent('table').addClass('table table-condensed'); } $(document).ready(function () { bootstrapStylePandocTables(); }); $(document).ready(function () { window.buildTabsets(\"TOC\"); }); $(document).ready(function () { $('.tabset-dropdown > .nav-tabs > li').click(function () { $(this).parent().toggleClass('nav-tabs-open'); }); }); (function () { var script = document.createElement(\"script\"); script.type = \"text/javascript\"; script.src = \"https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML\"; document.getElementsByTagName(\"head\")[0].appendChild(script); })();","categories":[],"tags":[]},{"title":"twitter API prac","slug":"twitter-API-prac","date":"2021-03-26T07:21:30.000Z","updated":"2021-03-26T12:53:13.618Z","comments":true,"path":"2021/03/26/twitter-API-prac/","link":"","permalink":"https://kjm94.github.io/2021/03/26/twitter-API-prac/","excerpt":"","text":"트위터 API 인증 https://apps.twitter.com 회원가입 한 뒤 create an app 클릭 후 진행 rtweet 패키지1234# install.packages(&quot;rtweet&quot;)library(rtweet)library(dplyr)library(ggplot2) search Tweets 함수12rstats &lt;- search_tweets(&quot;#테슬라&quot;, n = 1000, include_rts = FALSE) %&gt;% select(name, location, description) 1glimpse(rtats) api 사용자 토큰이 없어서 결과를 올리지 못함.","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"Rshiny setup","slug":"Rshiny-setup","date":"2021-03-25T08:08:18.000Z","updated":"2021-03-26T12:53:13.539Z","comments":true,"path":"2021/03/25/Rshiny-setup/","link":"","permalink":"https://kjm94.github.io/2021/03/25/Rshiny-setup/","excerpt":"","text":"R shiny setup setting12345install.packages(&#x27;rsconnect&#x27;)library(rsconnect)rsconnect::setAccountInfo(name=&#x27;kjm94&#x27;, token=&#x27;14A30ABF3A5B0831FAF5A8FFB145F970&#x27;, secret=&#x27;khn/qL4qNTXeph1BW5ycrB0plemummTXwss47pIA&#x27;)","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"R-ggplot No.1","slug":"R-ggplot","date":"2021-03-24T06:40:25.000Z","updated":"2021-03-26T12:53:13.533Z","comments":true,"path":"2021/03/24/R-ggplot/","link":"","permalink":"https://kjm94.github.io/2021/03/24/R-ggplot/","excerpt":"","text":"눈금 표시 방법123456ggplot(PlantGrowth, aes(x = group, y = weight)) + geom_boxplot() + scale_y_continuous(limits = c(0, 10), # 축 범위 breaks = c(1, 3, 5, 7, 9), # 축의 숫자 지정 labels = c(&quot;1st&quot;, &quot;three&quot;, &quot;five&quot;, &quot;seven&quot;, &quot;nine&quot;)) 범주형 축 항목 순서 변경하기1234ggplot(PlantGrowth, aes(x = group, weight)) + geom_boxplot() + theme_bw() + scale_x_discrete(limits = c(&quot;trt1&quot;, &quot;ctrl&quot;))","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"Random game 1","slug":"Random-game-1","date":"2021-03-23T12:55:42.000Z","updated":"2021-03-23T14:16:35.732Z","comments":true,"path":"2021/03/23/Random-game-1/","link":"","permalink":"https://kjm94.github.io/2021/03/23/Random-game-1/","excerpt":"","text":"가위바위보 1을 입력하면 가위 2를 입력하면 바위 3을 입력하면 보 컴퓨터가 내는 수는 판마다 랜덤(난수) 0을 입력하면 종료 0, 1, 2, 3을 제외한 숫자 입력시 예외처리 게임결과 출력 12345678910111213141516171819202122232425262728293031323334353637383940414243444546474849505152535455565758596061626364656667686970717273747576#include &lt;iostream&gt;#include &lt;string&gt;#include &lt;random&gt;using namespace std;string text_temp(int num)&#123; if (num == 1) &#123; return &quot;가위&quot;; &#125; else if (num == 2) &#123; return &quot;바위&quot;; &#125; else &#123; return &quot;보&quot;; &#125;&#125;int main()&#123; int Count = 1; int player; cout &lt;&lt; &quot;가위바위보&quot; &lt;&lt; endl; random_device rd; mt19937 gen(rd()); uniform_int_distribution&lt;int&gt; dis(1, 3); string com_out; while (1) &#123; int com = dis(gen); cout &lt;&lt; &quot;가위(1)바위(2)보(3)종료(0) : &quot;; cin &gt;&gt; player; Count++; if (player == 0) &#123; cout &lt;&lt; &quot;종료&quot; &lt;&lt; endl; break; &#125; else if (player == com) &#123; cout &lt;&lt; &quot;비겼습니다.&quot; &lt;&lt; endl; cout &lt;&lt; &quot;상대(&quot; &lt;&lt; text_temp(com) &lt;&lt; &quot;) : 플레이어(&quot; &lt;&lt; text_temp(player) &lt;&lt; &quot;)&quot; &lt;&lt; endl; &#125; else if ((player == 1 &amp;&amp; com == 3) || (player == 2 &amp;&amp; com == 1) || (player == 3 &amp;&amp; com == 2)) &#123; cout &lt;&lt; &quot;이겼습니다.&quot; &lt;&lt; endl; cout &lt;&lt; &quot;상대(&quot; &lt;&lt; text_temp(com) &lt;&lt; &quot;) : 플레이어(&quot; &lt;&lt; text_temp(player) &lt;&lt; &quot;)&quot; &lt;&lt; endl; &#125; else if (player &gt; 3) &#123; cout &lt;&lt; &quot;숫자는 1, 2, 3중에서만 입력해주세요.&quot; &lt;&lt; endl; &#125; else &#123; cout &lt;&lt; &quot;졌습니다.&quot; &lt;&lt; endl; cout &lt;&lt; &quot;상대(&quot; &lt;&lt; text_temp(com) &lt;&lt; &quot;) : 플레이어(&quot; &lt;&lt; text_temp(player) &lt;&lt; &quot;)&quot; &lt;&lt; endl; &#125; &#125; return 0;&#125;","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://kjm94.github.io/tags/C/"}]},{"title":"R test1","slug":"R-test1","date":"2021-03-23T07:21:09.000Z","updated":"2021-03-23T12:43:13.174Z","comments":true,"path":"2021/03/23/R-test1/","link":"","permalink":"https://kjm94.github.io/2021/03/23/R-test1/","excerpt":"","text":"패키지 설치 방법 ggplot2와 dplyr 패키지 설치 방법 기재 12install.package(&quot;ggplot2&quot;)install.package(&quot;dplyr&quot;) 패키지 설치 12library(ggplot2)library(dplyr) 라이브러리 연결 액셀 데이터 받아오기12counties &lt;- readxl::read_xlsx(&quot;파일위치/파일이름.xslx&quot;, sheet = 1)glimpse(counties) getwd()로 위치확인 후 진행할 것에 주의glimpse는 현재 데이터를 보여줌 private_work, unemployment를 활용하여 산점도를 작성 region을 기준으로 그룹화 12345ggplot(data = counties, # 데이터 aes(x = private_work, #x축 y = unemployment, #y축 colour = region)) # 색상 = region 4개geom_point() dplyr 함수를 활용하여, 아래 데이터 요약 counties 데이터를 활용합니다. 변수 추출은 region, state, men, women 각 region, state 별 men, wemen 전체 인구수를 구함. 최종 데이터셋 저장 이름은 final_df로 명명 123456789counties %&gt;% select(region, state, county, men, women) %&gt;% # select group_by(region, state) %&gt;% # group_by summarize(total_men = sum(men), #summarize total_women = sum(women)) %&gt;% # head()여기까지 끊는 함수 filter(region == &quot;North Central&quot;) %&gt;% arrange(desc(total_men)) -&gt; final_dfglimpse(final_df) final_df를 기준으로 막대 그래프를 그린다. x축 : state 1개의 region만 선택 12ggplot(final_df, aes(x = state, y = total_men)) +geom_col()","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"image upload","slug":"image-test","date":"2021-03-23T03:39:44.000Z","updated":"2021-03-23T12:43:13.174Z","comments":true,"path":"2021/03/23/image-test/","link":"","permalink":"https://kjm94.github.io/2021/03/23/image-test/","excerpt":"","text":"#이미지 올리기 1![](..&#x2F;image&#x2F;r_markdown&#x2F;pressure-1.png)","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"R aes","slug":"R-menu","date":"2021-03-23T03:19:54.000Z","updated":"2021-03-23T12:43:13.173Z","comments":true,"path":"2021/03/23/R-menu/","link":"","permalink":"https://kjm94.github.io/2021/03/23/R-menu/","excerpt":"","text":"getwd() 위치확인rm(list = ls()) 모두 지우기 12345678910111213141516171819library(ggplot2)ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, colours = Species)) + geom_point(size = 5) + theme_bw()ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, size = Petal.Length, colours = Species)) + geom_point() + theme_bw()ggplot(iris, aes(x = Sepal.Length, y = Sepal.Width, colours = Species)) + geom_point(size = 2) + theme_bw() aes(size = Petal.Lengh, colour = Species)전체 옵션 선택 : aes() 밖에서 = 그래프 종류각각의 데이터별로 옵션을 선택aes(안에서 옵션 설정, 변수명)customize –&gt; scale","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"base guide","slug":"abase-guide","date":"2021-03-23T02:57:22.000Z","updated":"2021-03-23T12:43:13.174Z","comments":true,"path":"2021/03/23/abase-guide/","link":"","permalink":"https://kjm94.github.io/2021/03/23/abase-guide/","excerpt":"","text":"깃허브에 소스 업로드1git remote 현재 폴더의 원격 레퍼지토리 확인 명령어 1git remote add 원격저장소이름 https:&#x2F;&#x2F;github.com&#x2F;유저네임&#x2F;레퍼지토리네임.git 깃허브 저장소의 주소로 원격저장소 생성 작업폴더와 깃허브 저장소가 연동됨. 1git push -u origin master push는 업로드 명령어 수정 후 업데이트123git add 파일명git commit -m &quot;msg&quot;git push commit은 수정한 내용에 대한 코멘터리 소스 내려 받기깃허브 원격 저장소의 Clone or download에서 주소를 복사 복사를 시킬 폴더 생성 IDE로 폴더 오픈 후, 터미널에서 클론 명령어 1git clone https:&#x2F;&#x2F;github.com&#x2F;유저네임&#x2F;원격저장소이름.git 내려받아진 폴더로 터미널 이동 1cd 폴더 깃 로그 명령어를 통해 이전 작업내용 확인가능 1git log 이전 반영된 파일 받아오기 1git pull 원격저장소명 브랜치명","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://kjm94.github.io/tags/git/"}]},{"title":"git clone","slug":"clone","date":"2021-03-23T02:52:27.000Z","updated":"2021-03-23T12:43:13.174Z","comments":true,"path":"2021/03/23/clone/","link":"","permalink":"https://kjm94.github.io/2021/03/23/clone/","excerpt":"","text":"1git clone --depth 1 https:&#x2F;&#x2F;github.com&#x2F;chinsun9&#x2F;refactor-2019T1.git commit history 없이 clone 하는 방법–depth 옵션–depth 1 -&gt; 가장 마지막 상태 클론","categories":[],"tags":[{"name":"git","slug":"git","permalink":"https://kjm94.github.io/tags/git/"}]},{"title":"R-DAY1","slug":"R-DAY1","date":"2021-03-22T05:28:16.000Z","updated":"2021-03-23T12:43:13.173Z","comments":true,"path":"2021/03/22/R-DAY1/","link":"","permalink":"https://kjm94.github.io/2021/03/22/R-DAY1/","excerpt":"","text":"12345# Factor 범주형 변수# 컴퓨터 &lt;- 숫자로 인식# 문자 숫자 논리형 순으로 저장# ordered = TRUE# levels = c(&quot;정렬&quot;) 12345678910111213141516171819202122232425262728# 1. 사람과 관련된 데이터# - 고객 데이터 (CRM)# 2. 기계와 관련된 데이터# - 제조공정과 관련된 데이터# install.packages(&quot;패키지&quot;) 패키지 설치# 1단계 : 패키지 불러오기install.packages(&quot;ggplot2&quot;)library(ggplot2)# 2단계 : 데이터 불러오기data(&quot;iris&quot;)# 3단계 : 데이터 확인str(iris)# 4단계 : 데이터 가공 하기 (시각화)# 5단계 : 시각화ggplot(data = iris, mapping = aes(x = Petal.Length, y = Petal.Width)) + geom_point() + geom_smooth(method=&quot;loess&quot;, se=F) + #xlim(c(0, 0.1)) + #ylim(c(0, 500000)) + labs(subtitle=&quot;Area Vs Population&quot;, y=&quot;Population&quot;, x=&quot;Area&quot;, title=&quot;Scatterplot&quot;, caption = &quot;Source: midwest&quot;)","categories":[],"tags":[{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"}]},{"title":"Adoring","slug":"Adoring","date":"2021-03-22T02:26:06.000Z","updated":"2021-03-23T12:43:13.173Z","comments":true,"path":"2021/03/22/Adoring/","link":"","permalink":"https://kjm94.github.io/2021/03/22/Adoring/","excerpt":"","text":"123456789#include &lt;iostream&gt;int main()&#123; std::cout&lt;&lt;&quot;첫번째 정수 입력 : &quot;; std::cin&gt;&gt; inum1; return 0;&#125;","categories":[],"tags":[{"name":"C++","slug":"C","permalink":"https://kjm94.github.io/tags/C/"}]},{"title":"practice","slug":"practice","date":"2021-03-22T02:21:48.000Z","updated":"2021-03-23T12:43:13.178Z","comments":true,"path":"2021/03/22/practice/","link":"","permalink":"https://kjm94.github.io/2021/03/22/practice/","excerpt":"","text":"1234a = 1b = 2c = a + bprint(c) 패키지 설치1","categories":[],"tags":[{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"}]},{"title":"temp","slug":"temp","date":"2021-03-22T02:08:46.000Z","updated":"2021-03-23T12:43:13.178Z","comments":true,"path":"2021/03/22/temp/","link":"","permalink":"https://kjm94.github.io/2021/03/22/temp/","excerpt":"","text":"R 설치 R을 설치한다. URL: https://www.r-project.org/소스코드 작성 R 소스코드를 작성합니다.1234a &lt;- 1b &lt;- 2c &lt;- a + bprint(c)","categories":[],"tags":[]}],"categories":[],"tags":[{"name":"Java","slug":"Java","permalink":"https://kjm94.github.io/tags/Java/"},{"name":"python","slug":"python","permalink":"https://kjm94.github.io/tags/python/"},{"name":"DL","slug":"DL","permalink":"https://kjm94.github.io/tags/DL/"},{"name":"C++","slug":"C","permalink":"https://kjm94.github.io/tags/C/"},{"name":"R","slug":"R","permalink":"https://kjm94.github.io/tags/R/"},{"name":"C","slug":"C","permalink":"https://kjm94.github.io/tags/C/"},{"name":"git","slug":"git","permalink":"https://kjm94.github.io/tags/git/"}]}